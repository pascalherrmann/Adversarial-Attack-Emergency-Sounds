{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze https://research.google.com/audioset///dataset/emergency_vehicle.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import youtube_dl\n",
    "import os\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from multiprocessing import Process\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "\n",
    "path_ontology = \"/nfs/students/summer-term-2020/project-4/data/dataset1/ontology/ontology.json\"\n",
    "path_train_unbalanced = \"/nfs/students/summer-term-2020/project-4/data/dataset1/audioSetCsv/unbalanced_train_segments.csv\"\n",
    "path_train_balanced = \"/nfs/students/summer-term-2020/project-4/data/dataset1/audioSetCsv/balanced_train_segments.csv\"\n",
    "path_eval_balanced = \"/nfs/students/summer-term-2020/project-4/data/dataset1/audioSetCsv/eval_segments.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadJsonFile(path):\n",
    "    if path[-5:] == '.json':\n",
    "        return json.load(open(path))\n",
    "    \n",
    "def loadCsvFile(path):\n",
    "    if path[-4:] == '.csv':\n",
    "        names = ['YTID', 'start_seconds', 'end_seconds', 'positive_labels']\n",
    "        return pd.read_csv(open(path), sep=', ', header=None, index_col=0, \n",
    "                           skiprows=3, names=names, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontoloy = loadJsonFile(path_ontology)\n",
    "train_unbalanced = loadCsvFile(path_train_unbalanced)\n",
    "train_balanced = loadCsvFile(path_train_balanced)\n",
    "eval_balanced = loadCsvFile(path_eval_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Motor vehicle (road) (/m/012f08)\n"
     ]
    }
   ],
   "source": [
    "for entry in ontoloy:\n",
    "    if 'Motor vehicle' in entry['name']:\n",
    "        print(\"\\t \" + entry['name'] + \" (\" + entry['id'] + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze ontology towards Emergency Vehicle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findChildren(ontology_id):\n",
    "    result = []\n",
    "    for entry in ontoloy:\n",
    "        if entry['id'] == ontology_id:\n",
    "            result.append(ontology_id)\n",
    "            for child_id in entry['child_ids']:\n",
    "                result.extend(findChildren(child_id))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_ids = []\n",
    "negative1_ids = []\n",
    "negative2_ids = []\n",
    "\n",
    "# https://research.google.com/audioset///ontology/emergency_vehicle_1.html\n",
    "positive_ids.extend(findChildren('/m/03j1ly')) \n",
    "\n",
    "# https://research.google.com/audioset///ontology/alarm_1.html\n",
    "negative1_ids.extend([x for x in findChildren('/m/07pp_mv') if x not in positive_ids])\n",
    "\n",
    "# https://research.google.com/audioset////ontology/motor_vehicle_road_1.html\n",
    "negative2_ids.extend([x for x in findChildren('/m/012f08') if x not in positive_ids]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printChildren(ontology_id, depth, list_of_ids):\n",
    "    for entry in ontoloy:\n",
    "        if entry['id'] == ontology_id and ontology_id in list_of_ids: \n",
    "            print(''.join([\"\\t\" for _ in range(depth)]) + entry['name'] + \" (\" + entry['id'] + \")\")\n",
    "            for child_id in entry['child_ids']:\n",
    "                printChildren(child_id, depth+1, list_of_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive classes:\n",
      "\tEmergency vehicle (/m/03j1ly)\n",
      "\t\tPolice car (siren) (/m/04qvtq)\n",
      "\t\tAmbulance (siren) (/m/012n7d)\n",
      "\t\tFire engine, fire truck (siren) (/m/012ndj)\n",
      "\n",
      "Negative classes 1:\n",
      "\tAlarm (/m/07pp_mv)\n",
      "\t\tTelephone (/m/07cx4)\n",
      "\t\t\tTelephone bell ringing (/m/07pp8cl)\n",
      "\t\t\tRingtone (/m/01hnzm)\n",
      "\t\t\tCellphone buzz, vibrating alert (/m/01sb50)\n",
      "\t\t\tTelephone dialing, DTMF (/m/02c8p)\n",
      "\t\t\tDial tone (/m/015jpf)\n",
      "\t\t\tBusy signal (/m/01z47d)\n",
      "\t\tAlarm clock (/m/046dlr)\n",
      "\t\tSiren (/m/03kmc9)\n",
      "\t\t\tCivil defense siren (/m/0dgbq)\n",
      "\t\tDoorbell (/m/03wwcy)\n",
      "\t\t\tDing-dong (/m/07r67yg)\n",
      "\t\tBuzzer (/m/030rvx)\n",
      "\t\tSmoke detector, smoke alarm (/m/01y3hg)\n",
      "\t\tFire alarm (/m/0c3f7m)\n",
      "\t\tCar alarm (/m/02mfyn)\n",
      "\t\tVehicle horn, car horn, honking (/m/0912c9)\n",
      "\t\t\tToot (/m/07qv_d5)\n",
      "\t\tBicycle bell (/m/0gy1t2s)\n",
      "\t\tAir horn, truck horn (/m/05x_td)\n",
      "\t\tFoghorn (/m/04fq5q)\n",
      "\t\tWhistle (/m/0l156k)\n",
      "\t\t\tKettle whistle (/g/11b630rrvh)\n",
      "\t\t\tSteam whistle (/m/06hck5)\n",
      "\n",
      "Negative classes 2:\n",
      "\tMotor vehicle (road) (/m/012f08)\n",
      "\t\tCar (/m/0k4j)\n",
      "\t\t\tVehicle horn, car horn, honking (/m/0912c9)\n",
      "\t\t\t\tToot (/m/07qv_d5)\n",
      "\t\t\tCar alarm (/m/02mfyn)\n",
      "\t\t\tPower windows, electric windows (/m/04gxbd)\n",
      "\t\t\tSkidding (/m/07rknqz)\n",
      "\t\t\tTire squeal (/m/0h9mv)\n",
      "\t\t\tCar passing by (/t/dd00134)\n",
      "\t\t\tRace car, auto racing (/m/0ltv)\n",
      "\t\tTruck (/m/07r04)\n",
      "\t\t\tAir brake (/m/0gvgw0)\n",
      "\t\t\tAir horn, truck horn (/m/05x_td)\n",
      "\t\t\tReversing beeps (/m/02rhddq)\n",
      "\t\t\tIce cream truck, ice cream van (/m/03cl9h)\n",
      "\t\tBus (/m/01bjv)\n",
      "\t\tMotorcycle (/m/04_sv)\n",
      "\t\tTraffic noise, roadway noise (/m/0btp2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive classes:\")\n",
    "# https://research.google.com/audioset///ontology/emergency_vehicle_1.html\n",
    "printChildren('/m/03j1ly', 1, positive_ids)\n",
    "    \n",
    "print()\n",
    "print(\"Negative classes 1:\")\n",
    "# https://research.google.com/audioset///ontology/alarm_1.html\n",
    "printChildren('/m/07pp_mv', 1, negative1_ids)\n",
    "\n",
    "print()\n",
    "print(\"Negative classes 2:\")\n",
    "# https://research.google.com/audioset///ontology/alarm_1.html\n",
    "printChildren('/m/012f08', 1, negative2_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_ids = negative1_ids + negative2_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryClassification(labels):\n",
    "    containsPositiveLabel = False\n",
    "    containsNegativeLabel = False\n",
    "    \n",
    "    for label in labels:\n",
    "        if label in positive_ids:\n",
    "            containsPositiveLabel = True\n",
    "    \n",
    "        if label in negative_ids:\n",
    "            containsNegativeLabel = True\n",
    "            \n",
    "    return containsPositiveLabel, containsNegativeLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPositiveSample(labels):\n",
    "    containsPositiveLabel, containsNegativeLabel = binaryClassification(labels)\n",
    "    # don't exclude samples with negative labels, \n",
    "    # as EM sounds sometimes labeled as siren as well (we deal with multi-labeling here)\n",
    "    return containsPositiveLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNegativeSample(labels):\n",
    "    containsPositiveLabel, containsNegativeLabel = binaryClassification(labels)\n",
    "    return not containsPositiveLabel and containsNegativeLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBinaryDatasetSamples(dataset):\n",
    "    positives = pd.DataFrame(data=None, columns=dataset.columns)\n",
    "    negatives = pd.DataFrame(data=None, columns=dataset.columns)\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        labels = row['positive_labels'].split(',')\n",
    "\n",
    "        isPositive = isPositiveSample(labels)\n",
    "        isNegative = isNegativeSample(labels)\n",
    "\n",
    "        if isPositive and not isNegative:\n",
    "            positives.loc[index]=row\n",
    "        elif not isPositive and isNegative:\n",
    "            negatives.loc[index]=row\n",
    "            \n",
    "    return positives, negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unbalanced_positives, train_unbalanced_negatives = getBinaryDatasetSamples(train_unbalanced)\n",
    "train_balanced_positives, train_balanced_negatives = getBinaryDatasetSamples(train_balanced)\n",
    "eval_balanced_positives, eval_balanced_negatives = getBinaryDatasetSamples(eval_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23852\n",
      "4257\n",
      "\n",
      "476\n",
      "121\n",
      "\n",
      "512\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "print(len(train_unbalanced_negatives))\n",
    "print(len(train_unbalanced_positives))\n",
    "print()\n",
    "print(len(train_balanced_negatives))\n",
    "print(len(train_balanced_positives))\n",
    "print()\n",
    "print(len(eval_balanced_negatives))\n",
    "print(len(eval_balanced_positives))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydl_opts = {\n",
    "    'quiet':'True',\n",
    "    'format': 'bestaudio/best',\n",
    "    'ignoreerrors':'True',\n",
    "    'no_warnings':'True',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'wav',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'outtmpl':'tmp/%(id)s.%(ext)s',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadDataset(dataset, save_path):\n",
    "    for index, row in dataset.iterrows():\n",
    "        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download(['http://www.youtube.com/watch?v=' + index])\n",
    "\n",
    "        name = index + '.wav'\n",
    "        path_downloaded = './tmp/' + name\n",
    "        path_final = save_path + name\n",
    "        start = row[0]\n",
    "        end = row[1]\n",
    "        \n",
    "        if os.path.exists(path_downloaded):\n",
    "            ffmpeg_extract_subclip(path_downloaded, start, end,targetname=path_final)\n",
    "            os.remove(path_downloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadDatasetParallelized(dataset, save_path):\n",
    "    num_cpus = multiprocessing.cpu_count()\n",
    "    listOfDfs = [dataset.loc[idx] for idx in np.array_split(dataset.index,num_cpus)]\n",
    "    print(\"Mean chunk size: \" + str(np.mean([len(x) for x in listOfDfs])))\n",
    "    \n",
    "    processes = []\n",
    "    for chunk in listOfDfs:\n",
    "        p = Process(target=downloadDataset, args=(chunk,save_path))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "        \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "        \n",
    "    dataset.to_csv(save_path + \"meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_unbalanced_negatives = \"/nfs/students/summer-term-2020/project-4/data/dataset1/download/training_unbalanced/negative/\"\n",
    "path_train_unbalanced_positives = \"/nfs/students/summer-term-2020/project-4/data/dataset1/download/training_unbalanced/positive/\"\n",
    "\n",
    "path_train_balanced_negatives = \"/nfs/students/summer-term-2020/project-4/data/dataset1/download/training_balanced/negative/\"\n",
    "path_train_balanced_positives = \"/nfs/students/summer-term-2020/project-4/data/dataset1/download/training_balanced/positive/\"\n",
    "\n",
    "path_eval_balanced_negatives = \"/nfs/students/summer-term-2020/project-4/data/dataset1/download/eval_balanced/negative/\"\n",
    "path_eval_balanced_positives = \"/nfs/students/summer-term-2020/project-4/data/dataset1/download/eval_balanced/positive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "downloadDatasetParallelized(train_unbalanced_negatives, path_train_unbalanced_negatives)\n",
    "downloadDatasetParallelized(train_unbalanced_positives, path_train_unbalanced_positives)\n",
    "\n",
    "downloadDatasetParallelized(train_balanced_negatives, path_train_balanced_negatives)\n",
    "downloadDatasetParallelized(train_balanced_positives, path_train_balanced_positives)\n",
    "\n",
    "downloadDatasetParallelized(eval_balanced_negatives, path_eval_balanced_negatives)\n",
    "downloadDatasetParallelized(eval_balanced_positives, path_eval_balanced_positives)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
