{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to train a model with PyTorch Lightning\n",
    "\n",
    "* Define your Model Class (in `classification/models`)\n",
    "    * just as usual, as a subclass of `nn.Module`, where you define architecture in the initializer and implement the forward path in `forward(self, x)`\n",
    "    * the outputs of the forward path must be of shape `[BATCH_SIZE, NUM_CLASSES]` \n",
    "* Also define your subclass of `PLModule`, i.e., PyTorch Lightning Module\n",
    "    * the PyTorch Lightning Module combines your model with the DataLoader and Solver specifics\n",
    "    * PyTorch Lightning will then run the training loop, log to TensorBoard, save checkpoints, etc.\n",
    "    * to create your PyTorch Lightning Module, you can simply inherit from `GeneralPLModule` and set `self.model` to your model\n",
    "    * if you want to customize further, you can overwrite functions from `GeneralPLModule`:\n",
    "       * e.g. `prepare_data(self)`, which sets `self.dataset[\"train\"]` and `self.dataset[\"val\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import numpy as np\n",
    "from M5 import M5, M5PLModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"weight_decay\": 0,\n",
    "    \"lr_decay\": 1\n",
    "}\n",
    "\n",
    "model = M5PLModule(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    gpus=1 if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from HyperParamSearch import MetricsCallback, save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # as explained above, we'll use this callback to collect the validation accuracies\n",
    "    metrics_callback = MetricsCallback()  \n",
    "    \n",
    "    # create a trainer\n",
    "    trainer = pl.Trainer(\n",
    "        logger=False,                                                                  # deactivate PL logging\n",
    "        max_epochs=3,                                                                  # epochs\n",
    "        gpus=1 if torch.cuda.is_available() else None,\n",
    "        callbacks=[metrics_callback],                                                  # save latest accuracy\n",
    "        early_stop_callback=PyTorchLightningPruningCallback(trial, monitor=\"val_acc\"), # early stopping\n",
    "    )\n",
    "\n",
    "    # here we sample the hyper params, similar as in our old random search\n",
    "    trial_hparams = {\"batch_size\": 64, \n",
    "                     \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-1),\n",
    "                     \"p_drop\": trial.suggest_float(\"p_drop\", 1e-6, 1e-1),\n",
    "                     \"lr_decay\": trial.suggest_float(\"lr_decay\", 1e-6, 1e-1),\n",
    "                     \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-1)\n",
    "                    }    \n",
    "\n",
    "    model = M5PLModule(trial_hparams)\n",
    "    trainer.fit(model)\n",
    "\n",
    "    # save model\n",
    "    save_model(model, '{}.p'.format(trial.number), \"checkpoints\")\n",
    "\n",
    "    print(\"metrics:\", metrics_callback.metrics)\n",
    "    # return validation accuracy from latest model, as that's what we want to minimize by our hyper param search\n",
    "    return metrics_callback.metrics[-1][\"val_acc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "study.optimize(objective, n_trials=3, timeout=21600)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(best_trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
