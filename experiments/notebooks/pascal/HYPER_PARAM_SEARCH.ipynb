{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from datasets.datasethandler import DatasetHandler\n",
    "datasetHandler = DatasetHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "from classification.models.M5 import M5PLModule\n",
    "from classification.models.SpectrogramCNN import SpectrogramCNNPLModule\n",
    "\n",
    "from classification.trainer.HyperParamSearch import MetricsCallback, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "class SaveBestCallback(Callback): \n",
    "    def __init__(self, model_name = \"newest_model\", add_v_number = True):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.best_val_acc = None\n",
    "        self.add_v_number = add_v_number\n",
    "\n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        if not self.best_val_acc or pl_module.val_results_history[-1][\"val_acc\"] > self.best_val_acc:\n",
    "            print(\"new best val acc\", pl_module.val_results_history[-1][\"val_acc\"])\n",
    "            self.best_val_acc = pl_module.val_results_history[-1][\"val_acc\"]\n",
    "            save_path = self.model_name + (( \"_v{}\".format(trainer.logger.version) +  \"_best.p\") if self.add_v_number else \"\")\n",
    "            pl_module.save(save_path)\n",
    "            print(\"Saved checkpoint at epoch {} at \\\"{}\\\"\".format((trainer.current_epoch + 1), save_path))\n",
    "\n",
    "cb = SaveBestCallback(\"optuna_spectro_2\", add_v_number = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-06-24 20:14:03,741]\u001b[0m A new study created with name: spectrogram_study\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    metrics_callback = MetricsCallback()  \n",
    "        \n",
    "    # here we sample the hyper params, similar as in our old random search\n",
    "    trial_hparams = {\"batch_size\": trial.suggest_categorical('batch_size', [2,4,8,16,32,64]),\n",
    "                     \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-1),\n",
    "                     \"p_drop\": trial.suggest_float(\"p_drop\", 0, 0.),\n",
    "                     \"lr_decay\": trial.suggest_float(\"lr_decay\", 0.75, 1),\n",
    "                     \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-1)\n",
    "                    }    \n",
    "\n",
    "    model = SpectrogramCNNPLModule(trial_hparams)\n",
    "    \n",
    "    # create a trainer\n",
    "    trainer = pl.Trainer(\n",
    "        logger=pl.loggers.TensorBoardLogger(config.LOG_DIR, name=type(model.model).__name__),\n",
    "        max_epochs=30,                                                               \n",
    "        gpus=1 if torch.cuda.is_available() else None,\n",
    "        callbacks=[metrics_callback, cb],                                                         # save latest accuracy\n",
    "        early_stop_callback=PyTorchLightningPruningCallback(trial, monitor=\"validation_acc\"), # early stopping\n",
    "    )\n",
    "    \n",
    "    datasetHandler.load(model, 'training')\n",
    "    datasetHandler.load(model, 'validation')\n",
    "    trainer.fit(model)\n",
    "\n",
    "    # save model\n",
    "    model.save(\"saved_models\"+'{}.p'.format(trial.number))\n",
    "\n",
    "    # return validation accuracy from latest model, as that's what we want to minimize by our hyper param search\n",
    "    return metrics_callback.metrics[-1][\"validation_acc\"]\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner, study_name='spectrogram_study', storage='sqlite:///spectrogram_study.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load: /nfs/students/summer-term-2020/project-4/data/dataset1/dataset_resampled/training.p\n",
      "Load: /nfs/students/summer-term-2020/project-4/data/dataset1/dataset_resampled/validation.p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name        | Type           | Params\n",
      "-------------------------------------------\n",
      "0  | model       | SpectrogramCNN | 338 K \n",
      "1  | model.bn0   | BatchNorm2d    | 2     \n",
      "2  | model.conv1 | Conv2d         | 505   \n",
      "3  | model.bn1   | BatchNorm2d    | 10    \n",
      "4  | model.conv2 | Conv2d         | 2 K   \n",
      "5  | model.bn2   | BatchNorm2d    | 10    \n",
      "6  | model.conv3 | Conv2d         | 20 K  \n",
      "7  | model.bn3   | BatchNorm2d    | 20    \n",
      "8  | model.conv4 | Conv2d         | 60 K  \n",
      "9  | model.bn4   | BatchNorm2d    | 30    \n",
      "10 | model.fc1   | Linear         | 255 K \n",
      "11 | model.fc2   | Linear         | 102   \n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.03852993479549496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513d94b39165439bb4926f2461fdb71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.8435091879075282\n",
      "new best val acc 0.8435091879075282\n",
      "Saved model to \"optuna_spectro_2\"\n",
      "Saved checkpoint at epoch 1 at \"optuna_spectro_2\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.7842323651452282\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=1000, timeout=21600) #6h\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "print(\"  Value: {}\".format(best_trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out v-num 5\n",
    "\n",
    "# morgen: nochmal schnell paar mal mit num_iter trainieren.\n",
    "#trial 10-1: 17 epochs -> 89.3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
