{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "from classification.models.M5 import M5PLModule\n",
    "from classification.trainer.HyperParamSearch import MetricsCallback, save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    metrics_callback = MetricsCallback()  \n",
    "    \n",
    "    # create a trainer\n",
    "    trainer = pl.Trainer(\n",
    "        logger=None, #loggers.TensorBoardLogger(config.LOG_DIR, name=\"M5\"),\n",
    "        max_epochs=2,                                                               \n",
    "        gpus=1 if torch.cuda.is_available() else None,\n",
    "        callbacks=[metrics_callback],                                                  # save latest accuracy\n",
    "        early_stop_callback=PyTorchLightningPruningCallback(trial, monitor=\"val_acc\"), # early stopping\n",
    "    )\n",
    "    \n",
    "    #trial.logger_version = trainer.logger.version\n",
    "\n",
    "    # here we sample the hyper params, similar as in our old random search\n",
    "    trial_hparams = {\"batch_size\": trial.suggest_categorical('batch_size', [64]),\n",
    "                     \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-1),\n",
    "                     \"p_drop\": trial.suggest_float(\"p_drop\", 0, 0.),\n",
    "                     \"lr_decay\": trial.suggest_float(\"lr_decay\", 0.8, 1),\n",
    "                     \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-1)\n",
    "                    }    \n",
    "\n",
    "    model = M5PLModule(trial_hparams)\n",
    "    trainer.fit(model)\n",
    "\n",
    "    # save model\n",
    "    save_model(model, '{}.p'.format(trial.number), \"saved_models\")\n",
    "\n",
    "    # return validation accuracy from latest model, as that's what we want to minimize by our hyper param search\n",
    "    return metrics_callback.metrics[-1][\"val_acc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached train data from /nfs/students/summer-term-2020/project-4/data/data_8k\n",
      "Loading cached val data from /nfs/students/summer-term-2020/project-4/data/data_8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name           | Type         | Params\n",
      "--------------------------------------------\n",
      "0  | model          | M5           | 555 K \n",
      "1  | model.model    | Sequential   | 555 K \n",
      "2  | model.model.0  | Conv1d       | 10 K  \n",
      "3  | model.model.1  | BatchNorm1d  | 256   \n",
      "4  | model.model.2  | MaxPool1d    | 0     \n",
      "5  | model.model.3  | Dropout      | 0     \n",
      "6  | model.model.4  | Conv1d       | 49 K  \n",
      "7  | model.model.5  | BatchNorm1d  | 256   \n",
      "8  | model.model.6  | MaxPool1d    | 0     \n",
      "9  | model.model.7  | Dropout      | 0     \n",
      "10 | model.model.8  | Conv1d       | 98 K  \n",
      "11 | model.model.9  | BatchNorm1d  | 512   \n",
      "12 | model.model.10 | MaxPool1d    | 0     \n",
      "13 | model.model.11 | Dropout      | 0     \n",
      "14 | model.model.12 | Conv1d       | 393 K \n",
      "15 | model.model.13 | BatchNorm1d  | 1 K   \n",
      "16 | model.model.14 | MaxPool1d    | 0     \n",
      "17 | model.model.15 | AvgPool1d    | 0     \n",
      "18 | model.model.16 | PermuteLayer | 0     \n",
      "19 | model.model.17 | Linear       | 1 K   \n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.03793716656787196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff34b4073685439cba2812ddaf8a36cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.8085358624777712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-06-20 00:02:08,834]\u001b[0m Finished trial#0 with value: 0.8203912270302312 with parameters: {'batch_size': 64, 'learning_rate': 0.0005678995288928688, 'p_drop': 0, 'lr_decay': 0.8064880168139812, 'weight_decay': 0.0009335941476504861}. Best is trial#0 with value: 0.8203912270302312.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.8203912270302312\n",
      "\n",
      "Number of finished trials: 1\n",
      "Best trial:\n",
      "  Value: 0.8203912270302312\n",
      "  Params: \n",
      "    batch_size: 64\n",
      "    learning_rate: 0.0005678995288928688\n",
      "    p_drop: 0\n",
      "    lr_decay: 0.8064880168139812\n",
      "    weight_decay: 0.0009335941476504861\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "study.optimize(objective, n_trials=1, timeout=21600) #6h\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "print(\"  Value: {}\".format(best_trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
