{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached train data from /nfs/students/summer-term-2020/project-4/data/data_8k\n",
      "Loading cached val data from /nfs/students/summer-term-2020/project-4/data/data_8k\n"
     ]
    }
   ],
   "source": [
    "from classification.models.M5 import M5, M5PLModule\n",
    "\n",
    "hparams = {\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"lr_decay\": 0.95\n",
    "}\n",
    "\n",
    "model = M5PLModule(hparams)\n",
    "model.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached train data from /nfs/students/summer-term-2020/project-4/data/data_8k\n",
      "Loading cached val data from /nfs/students/summer-term-2020/project-4/data/data_8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name           | Type         | Params\n",
      "--------------------------------------------\n",
      "0  | model          | M5           | 555 K \n",
      "1  | model.model    | Sequential   | 555 K \n",
      "2  | model.model.0  | Conv1d       | 10 K  \n",
      "3  | model.model.1  | BatchNorm1d  | 256   \n",
      "4  | model.model.2  | MaxPool1d    | 0     \n",
      "5  | model.model.3  | Dropout      | 0     \n",
      "6  | model.model.4  | Conv1d       | 49 K  \n",
      "7  | model.model.5  | BatchNorm1d  | 256   \n",
      "8  | model.model.6  | MaxPool1d    | 0     \n",
      "9  | model.model.7  | Dropout      | 0     \n",
      "10 | model.model.8  | Conv1d       | 98 K  \n",
      "11 | model.model.9  | BatchNorm1d  | 512   \n",
      "12 | model.model.10 | MaxPool1d    | 0     \n",
      "13 | model.model.11 | Dropout      | 0     \n",
      "14 | model.model.12 | Conv1d       | 393 K \n",
      "15 | model.model.13 | BatchNorm1d  | 1 K   \n",
      "16 | model.model.14 | MaxPool1d    | 0     \n",
      "17 | model.model.15 | AvgPool1d    | 0     \n",
      "18 | model.model.16 | PermuteLayer | 0     \n",
      "19 | model.model.17 | Linear       | 1 K   \n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.03734439834024896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd411dc6c15e4d91b15b73ee04ffcd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.8079430942501482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.8251333728512151\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    "    logger= loggers.TensorBoardLogger(config.LOG_DIR, name=\"M5\"),\n",
    "    gpus=1 if torch.cuda.is_available() else None,\n",
    "    log_gpu_memory='all'\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment I: Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached train data from /nfs/students/summer-term-2020/project-4/data/data_8k\n",
      "Loading cached val data from /nfs/students/summer-term-2020/project-4/data/data_8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name           | Type         | Params\n",
      "--------------------------------------------\n",
      "0  | model          | M5           | 555 K \n",
      "1  | model.model    | Sequential   | 555 K \n",
      "2  | model.model.0  | Conv1d       | 10 K  \n",
      "3  | model.model.1  | BatchNorm1d  | 256   \n",
      "4  | model.model.2  | MaxPool1d    | 0     \n",
      "5  | model.model.3  | Dropout      | 0     \n",
      "6  | model.model.4  | Conv1d       | 49 K  \n",
      "7  | model.model.5  | BatchNorm1d  | 256   \n",
      "8  | model.model.6  | MaxPool1d    | 0     \n",
      "9  | model.model.7  | Dropout      | 0     \n",
      "10 | model.model.8  | Conv1d       | 98 K  \n",
      "11 | model.model.9  | BatchNorm1d  | 512   \n",
      "12 | model.model.10 | MaxPool1d    | 0     \n",
      "13 | model.model.11 | Dropout      | 0     \n",
      "14 | model.model.12 | Conv1d       | 393 K \n",
      "15 | model.model.13 | BatchNorm1d  | 1 K   \n",
      "16 | model.model.14 | MaxPool1d    | 0     \n",
      "17 | model.model.15 | AvgPool1d    | 0     \n",
      "18 | model.model.16 | PermuteLayer | 0     \n",
      "19 | model.model.17 | Linear       | 1 K   \n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.03793716656787196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46996a2df5e459aa5bd9d05dd4cf310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.7374036751630113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.7990515708358032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.7344398340248963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.7397747480735033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading cached train data from /nfs/students/summer-term-2020/project-4/data/data_8k\n",
      "Loading cached val data from /nfs/students/summer-term-2020/project-4/data/data_8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name           | Type         | Params\n",
      "--------------------------------------------\n",
      "0  | model          | M5           | 555 K \n",
      "1  | model.model    | Sequential   | 555 K \n",
      "2  | model.model.0  | Conv1d       | 10 K  \n",
      "3  | model.model.1  | BatchNorm1d  | 256   \n",
      "4  | model.model.2  | MaxPool1d    | 0     \n",
      "5  | model.model.3  | Dropout      | 0     \n",
      "6  | model.model.4  | Conv1d       | 49 K  \n",
      "7  | model.model.5  | BatchNorm1d  | 256   \n",
      "8  | model.model.6  | MaxPool1d    | 0     \n",
      "9  | model.model.7  | Dropout      | 0     \n",
      "10 | model.model.8  | Conv1d       | 98 K  \n",
      "11 | model.model.9  | BatchNorm1d  | 512   \n",
      "12 | model.model.10 | MaxPool1d    | 0     \n",
      "13 | model.model.11 | Dropout      | 0     \n",
      "14 | model.model.12 | Conv1d       | 393 K \n",
      "15 | model.model.13 | BatchNorm1d  | 1 K   \n",
      "16 | model.model.14 | MaxPool1d    | 0     \n",
      "17 | model.model.15 | AvgPool1d    | 0     \n",
      "18 | model.model.16 | PermuteLayer | 0     \n",
      "19 | model.model.17 | Linear       | 1 K   \n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.04030823947836396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea48b62f64c543a69f812572c2039cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from attacks.FGA_Batch import fast_gradient_attack \n",
    "\n",
    "attack_args = [{\"norm\":\"2\", \"epsilon\":[15,100]},{\"norm\":\"inf\", \"epsilon\":[0.01, 0.3]}]\n",
    "def adv_train(attack_args):\n",
    "    for i in range(len(attack_args)):\n",
    "        model = M5PLModule(hparams)\n",
    "        model.attack_fn = fast_gradient_attack\n",
    "        model.attack_args = attack_args[i]\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=300,\n",
    "            logger= loggers.TensorBoardLogger(config.LOG_DIR, name=\"M5\"),\n",
    "            gpus=1 if torch.cuda.is_available() else None,\n",
    "            log_gpu_memory='all'\n",
    "        )\n",
    "        trainer.fit(model)\n",
    "\n",
    "        torch.save( {\"state_dict\": model.model.state_dict(), \"hparams\": model.hparams, \"attack_args\": attack_args[i]}, \"2first_search_{}.pt\".format(i))\n",
    "\n",
    "\n",
    "adv_train(attack_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **experiment** evaluates the robustness of **a given model** on **multiple specified attacks**\n",
    "* loads PL-Module (Model + Data)\n",
    "* creates new folder in experiments directory: number_description (for now, we can add e.g. data, git-user, ...) -> make sure to include model-name in description and maybe short attack summary. wobei... wenn sich das nur für die models ändert....\n",
    "* provide: different attacks you \n",
    "\n",
    "\n",
    "\n",
    "### Documentation\n",
    "* you define an experiment: an object of class `utils.RobustnessExperiment`.\n",
    "    * pass a title & description for the experiment (optional)\n",
    "    * pass different attacks + a list of configs, e.g.    \n",
    "    \n",
    "```python\n",
    "\n",
    "exp_config = [           \n",
    "              {\n",
    "               \"attack_fn\": fast_gradient_attack, \n",
    "               \"attack_arg\": {\"norm\":[\"inf\"], \"epsilon\": [0, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1]},\n",
    "               \"meta\": {\"key_result\":\"acc\", \"key_config\":\"epsilon\", \"title\":\"FGSM\"}\n",
    "              }\n",
    "            ]\n",
    "```\n",
    "\n",
    "* you then can **run** the experiment by passing a **model**\n",
    "* the following will happen:\n",
    "    * initializing of the experiment creates a folder in the dir specified in config, named ID_title (for now, we can add e.g. data, git_user, ... later). Also a pickle file will be saved to the directory.\n",
    "    * if you run an attack:\n",
    "        * a sub-folder in that directory will be created for the model.\n",
    "        * all attacks will be ran\n",
    "        * for every attack, a plot will be created\n",
    "        * one json (i.e. one for each model) will be saved to the directory\n",
    "        * also some samples are stored for each attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Dir '/nfs/students/summer-term-2020/project-4/experiments/0006_Test'\n",
      "Loading cached train data from /nfs/students/summer-term-2020/project-4/data/data_8k\n",
      "Loading cached val data from /nfs/students/summer-term-2020/project-4/data/data_8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Dir '/nfs/students/summer-term-2020/project-4/experiments/0006_Test/adv_totaly_hig_50epochs.pt'\n",
      "Perform Attack #1/2: FGSM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:28<00:00,  3.62s/it]"
     ]
    }
   ],
   "source": [
    "from utils.RobustnessExperiment import RobustnessExperiment\n",
    "from attacks.FGA_Batch import fast_gradient_attack\n",
    "\n",
    "exp_config = [{\n",
    "              \"attack_fn\": fast_gradient_attack, \n",
    "              \"attack_arg\": {\"norm\":[\"inf\"], \"epsilon\": [0, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1]},\n",
    "              \"meta\": {\"key_result\":\"acc\", \"key_config\":\"epsilon\", \"title\":\"FGSM\"}\n",
    "             },\n",
    "             {\n",
    "              \"attack_fn\": fast_gradient_attack, \n",
    "              \"attack_arg\": {\"norm\":[\"2\"], \"epsilon\": [0, 1, 2, 5, 10, 20, 50, 100]},\n",
    "              \"meta\": {\"key_result\":\"acc\", \"key_config\":\"epsilon\", \"title\":\"FGA L2\"}\n",
    "             }]\n",
    "\n",
    "experiment = RobustnessExperiment(exp_config, title=\"Test\")\n",
    "experiment.run(\"/nfs/homedirs/herrmanp/project-4/experiments/notebooks/pascal/adv_totaly_hig_50epochs.pt\", M5PLModule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
