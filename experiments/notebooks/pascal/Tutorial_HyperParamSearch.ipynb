{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "from classification.models.M5 import M5PLModule\n",
    "from classification.trainer.HyperParamSearch import MetricsCallback, save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    metrics_callback = MetricsCallback()  \n",
    "    \n",
    "    # create a trainer\n",
    "    trainer = pl.Trainer(\n",
    "        logger=None, #loggers.TensorBoardLogger(config.LOG_DIR, name=\"M5\"),\n",
    "        max_epochs=2,                                                               \n",
    "        gpus=1 if torch.cuda.is_available() else None,\n",
    "        callbacks=[metrics_callback],                                                  # save latest accuracy\n",
    "        early_stop_callback=PyTorchLightningPruningCallback(trial, monitor=\"val_acc\"), # early stopping\n",
    "    )\n",
    "    \n",
    "    #trial.logger_version = trainer.logger.version\n",
    "\n",
    "    # here we sample the hyper params, similar as in our old random search\n",
    "    trial_hparams = {\"batch_size\": trial.suggest_categorical('batch_size', [64]),\n",
    "                     \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-1),\n",
    "                     \"p_drop\": trial.suggest_float(\"p_drop\", 0, 0.),\n",
    "                     \"lr_decay\": trial.suggest_float(\"lr_decay\", 0.8, 1),\n",
    "                     \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-1)\n",
    "                    }    \n",
    "\n",
    "    model = M5PLModule(trial_hparams)\n",
    "    trainer.fit(model)\n",
    "\n",
    "    # save model\n",
    "    save_model(model, '{}.p'.format(trial.number), \"saved_models\")\n",
    "\n",
    "    # return validation accuracy from latest model, as that's what we want to minimize by our hyper param search\n",
    "    return metrics_callback.metrics[-1][\"val_acc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached train data from /nfs/students/summer-term-2020/project-4/data/data_8k\n",
      "Loading cached val data from /nfs/students/summer-term-2020/project-4/data/data_8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name           | Type         | Params\n",
      "--------------------------------------------\n",
      "0  | model          | M5           | 555 K \n",
      "1  | model.model    | Sequential   | 555 K \n",
      "2  | model.model.0  | Conv1d       | 10 K  \n",
      "3  | model.model.1  | BatchNorm1d  | 256   \n",
      "4  | model.model.2  | MaxPool1d    | 0     \n",
      "5  | model.model.3  | Dropout      | 0     \n",
      "6  | model.model.4  | Conv1d       | 49 K  \n",
      "7  | model.model.5  | BatchNorm1d  | 256   \n",
      "8  | model.model.6  | MaxPool1d    | 0     \n",
      "9  | model.model.7  | Dropout      | 0     \n",
      "10 | model.model.8  | Conv1d       | 98 K  \n",
      "11 | model.model.9  | BatchNorm1d  | 512   \n",
      "12 | model.model.10 | MaxPool1d    | 0     \n",
      "13 | model.model.11 | Dropout      | 0     \n",
      "14 | model.model.12 | Conv1d       | 393 K \n",
      "15 | model.model.13 | BatchNorm1d  | 1 K   \n",
      "16 | model.model.14 | MaxPool1d    | 0     \n",
      "17 | model.model.15 | AvgPool1d    | 0     \n",
      "18 | model.model.16 | PermuteLayer | 0     \n",
      "19 | model.model.17 | Linear       | 1 K   \n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: Checkpoint directory /nfs/homedirs/herrmanp/project-4/experiments/notebooks/pascal/checkpoints exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.03793716656787196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b72f829fa14559a39a335f848dfe04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.8103141671606402\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-06-09 15:20:45,014]\u001b[0m Finished trial#0 with value: 0.8251333728512151 with parameters: {'batch_size': 64, 'learning_rate': 0.0005526446899718101, 'p_drop': 0, 'lr_decay': 0.8004671484264645, 'weight_decay': 0.013578867935547207}. Best is trial#0 with value: 0.8251333728512151.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.8251333728512151\n",
      "\n",
      "Loading cached train data from /nfs/students/summer-term-2020/project-4/data/data_8k\n",
      "Loading cached val data from /nfs/students/summer-term-2020/project-4/data/data_8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name           | Type         | Params\n",
      "--------------------------------------------\n",
      "0  | model          | M5           | 555 K \n",
      "1  | model.model    | Sequential   | 555 K \n",
      "2  | model.model.0  | Conv1d       | 10 K  \n",
      "3  | model.model.1  | BatchNorm1d  | 256   \n",
      "4  | model.model.2  | MaxPool1d    | 0     \n",
      "5  | model.model.3  | Dropout      | 0     \n",
      "6  | model.model.4  | Conv1d       | 49 K  \n",
      "7  | model.model.5  | BatchNorm1d  | 256   \n",
      "8  | model.model.6  | MaxPool1d    | 0     \n",
      "9  | model.model.7  | Dropout      | 0     \n",
      "10 | model.model.8  | Conv1d       | 98 K  \n",
      "11 | model.model.9  | BatchNorm1d  | 512   \n",
      "12 | model.model.10 | MaxPool1d    | 0     \n",
      "13 | model.model.11 | Dropout      | 0     \n",
      "14 | model.model.12 | Conv1d       | 393 K \n",
      "15 | model.model.13 | BatchNorm1d  | 1 K   \n",
      "16 | model.model.14 | MaxPool1d    | 0     \n",
      "17 | model.model.15 | AvgPool1d    | 0     \n",
      "18 | model.model.16 | PermuteLayer | 0     \n",
      "19 | model.model.17 | Linear       | 1 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.03793716656787196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3111c83ea0471dabdebec4e72fa819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.7990515708358032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-06-09 15:21:08,166]\u001b[0m Finished trial#1 with value: 0.8180201541197392 with parameters: {'batch_size': 64, 'learning_rate': 3.657479021972008e-05, 'p_drop': 0, 'lr_decay': 0.9985837395665875, 'weight_decay': 0.08198542382441497}. Best is trial#0 with value: 0.8251333728512151.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.8180201541197392\n",
      "\n",
      "Loading cached train data from /nfs/students/summer-term-2020/project-4/data/data_8k\n",
      "Loading cached val data from /nfs/students/summer-term-2020/project-4/data/data_8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name           | Type         | Params\n",
      "--------------------------------------------\n",
      "0  | model          | M5           | 555 K \n",
      "1  | model.model    | Sequential   | 555 K \n",
      "2  | model.model.0  | Conv1d       | 10 K  \n",
      "3  | model.model.1  | BatchNorm1d  | 256   \n",
      "4  | model.model.2  | MaxPool1d    | 0     \n",
      "5  | model.model.3  | Dropout      | 0     \n",
      "6  | model.model.4  | Conv1d       | 49 K  \n",
      "7  | model.model.5  | BatchNorm1d  | 256   \n",
      "8  | model.model.6  | MaxPool1d    | 0     \n",
      "9  | model.model.7  | Dropout      | 0     \n",
      "10 | model.model.8  | Conv1d       | 98 K  \n",
      "11 | model.model.9  | BatchNorm1d  | 512   \n",
      "12 | model.model.10 | MaxPool1d    | 0     \n",
      "13 | model.model.11 | Dropout      | 0     \n",
      "14 | model.model.12 | Conv1d       | 393 K \n",
      "15 | model.model.13 | BatchNorm1d  | 1 K   \n",
      "16 | model.model.14 | MaxPool1d    | 0     \n",
      "17 | model.model.15 | AvgPool1d    | 0     \n",
      "18 | model.model.16 | PermuteLayer | 0     \n",
      "19 | model.model.17 | Linear       | 1 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.03023117960877297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becd9592b0d74c838ef978339c07f3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.6147006520450504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-06-09 15:21:30,096]\u001b[0m Finished trial#2 with value: 0.5631298162418494 with parameters: {'batch_size': 64, 'learning_rate': 0.011553366485236343, 'p_drop': 0, 'lr_decay': 0.9363953371402909, 'weight_decay': 0.05749691282766589}. Best is trial#0 with value: 0.8251333728512151.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.5631298162418494\n",
      "\n",
      "Loading cached train data from /nfs/students/summer-term-2020/project-4/data/data_8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name           | Type         | Params\n",
      "--------------------------------------------\n",
      "0  | model          | M5           | 555 K \n",
      "1  | model.model    | Sequential   | 555 K \n",
      "2  | model.model.0  | Conv1d       | 10 K  \n",
      "3  | model.model.1  | BatchNorm1d  | 256   \n",
      "4  | model.model.2  | MaxPool1d    | 0     \n",
      "5  | model.model.3  | Dropout      | 0     \n",
      "6  | model.model.4  | Conv1d       | 49 K  \n",
      "7  | model.model.5  | BatchNorm1d  | 256   \n",
      "8  | model.model.6  | MaxPool1d    | 0     \n",
      "9  | model.model.7  | Dropout      | 0     \n",
      "10 | model.model.8  | Conv1d       | 98 K  \n",
      "11 | model.model.9  | BatchNorm1d  | 512   \n",
      "12 | model.model.10 | MaxPool1d    | 0     \n",
      "13 | model.model.11 | Dropout      | 0     \n",
      "14 | model.model.12 | Conv1d       | 393 K \n",
      "15 | model.model.13 | BatchNorm1d  | 1 K   \n",
      "16 | model.model.14 | MaxPool1d    | 0     \n",
      "17 | model.model.15 | AvgPool1d    | 0     \n",
      "18 | model.model.16 | PermuteLayer | 0     \n",
      "19 | model.model.17 | Linear       | 1 K   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached val data from /nfs/students/summer-term-2020/project-4/data/data_8k\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.03793716656787196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78069bbad26946bf93c4edb9aa47f7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "\u001b[33m[W 2020-06-09 15:21:37,779]\u001b[0m Setting status of trial#3 as TrialState.FAIL because of the following error: IndexError('list index out of range')\n",
      "Traceback (most recent call last):\n",
      "  File \"/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/optuna/study.py\", line 734, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-4-b7a8d267ec64>\", line 30, in objective\n",
      "    return metrics_callback.metrics[-1][\"val_acc\"]\n",
      "IndexError: list index out of range\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5499bea4a8d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpruner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpruner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21600\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#6h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of finished trials: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 self._optimize_sequential(\n\u001b[0m\u001b[1;32m    339\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                 )\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    680\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001b[0;32m<ipython-input-4-b7a8d267ec64>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# return validation accuracy from latest model, as that's what we want to minimize by our hyper param search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "study.optimize(objective, n_trials=100, timeout=21600) #6h\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(best_trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
