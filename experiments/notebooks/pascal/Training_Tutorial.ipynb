{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to train a model with PyTorch Lightning\n",
    "\n",
    "* Define your Model Class (in `classification/models`)\n",
    "    * just as usual, as a subclass of `nn.Module`, where you define architecture in the initializer and implement the forward path in `forward(self, x)`\n",
    "    * the outputs of the forward path must be of shape `[BATCH_SIZE, NUM_CLASSES]` \n",
    "* Also define your subclass of `PLModule`, i.e., PyTorch Lightning Module\n",
    "    * the PyTorch Lightning Module combines your model with the DataLoader and Solver specifics\n",
    "    * PyTorch Lightning will then run the training loop, log to TensorBoard, save checkpoints, etc.\n",
    "    * to create your PyTorch Lightning Module, you can simply inherit from `GeneralPLModule` and set `self.model` to your model\n",
    "    * if you want to customize further, you can overwrite functions from `GeneralPLModule`:\n",
    "       * e.g. `prepare_data(self)`, which sets `self.dataset[\"train\"]` and `self.dataset[\"val\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Training\n",
    "\n",
    "If you want to perform adversarial training, set `model.attack = True`.\n",
    "\n",
    "You can also pass a custom attack (set `model.attack_function`) and arguments for that attack (set `model.attack_args`).\n",
    "\n",
    "The attack function must take a whole batch of inputs (if it only take a single input, simply change batchsize to 1) and return the perturbed inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached train data from /nfs/students/summer-term-2020/project-4/data/data_8k\n",
      "Loading cached val data from /nfs/students/summer-term-2020/project-4/data/data_8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name           | Type         | Params\n",
      "--------------------------------------------\n",
      "0  | model          | M5           | 555 K \n",
      "1  | model.model    | Sequential   | 555 K \n",
      "2  | model.model.0  | Conv1d       | 10 K  \n",
      "3  | model.model.1  | BatchNorm1d  | 256   \n",
      "4  | model.model.2  | MaxPool1d    | 0     \n",
      "5  | model.model.3  | Dropout      | 0     \n",
      "6  | model.model.4  | Conv1d       | 49 K  \n",
      "7  | model.model.5  | BatchNorm1d  | 256   \n",
      "8  | model.model.6  | MaxPool1d    | 0     \n",
      "9  | model.model.7  | Dropout      | 0     \n",
      "10 | model.model.8  | Conv1d       | 98 K  \n",
      "11 | model.model.9  | BatchNorm1d  | 512   \n",
      "12 | model.model.10 | MaxPool1d    | 0     \n",
      "13 | model.model.11 | Dropout      | 0     \n",
      "14 | model.model.12 | Conv1d       | 393 K \n",
      "15 | model.model.13 | BatchNorm1d  | 1 K   \n",
      "16 | model.model.14 | MaxPool1d    | 0     \n",
      "17 | model.model.15 | AvgPool1d    | 0     \n",
      "18 | model.model.16 | PermuteLayer | 0     \n",
      "19 | model.model.17 | Linear       | 1 K   \n",
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/herrmanp/miniconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.03793716656787196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e63ebaae8f64883b3fe26539030830d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val-Acc=0.7830468286899822\n"
     ]
    }
   ],
   "source": [
    "from attacks.FGA_Batch import fast_gradient_attack \n",
    "\n",
    "model_adv = M5PLModule(hparams)\n",
    "model_adv.attack_fn = fast_gradient_attack\n",
    "model_adv.attack_args = {\"norm\":\"inf\", \"epsilon\":[0.01, 0.2]}\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    "    logger= loggers.TensorBoardLogger(config.LOG_DIR, name=\"M5\"),\n",
    "    gpus=1 if torch.cuda.is_available() else None,\n",
    "    log_gpu_memory='all'\n",
    ")\n",
    "trainer.fit(model_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.report()\n",
    "print(\"\\nAttack:\")\n",
    "_ = model.report(attack=fast_gradient_attack, attack_args = {\"norm\":\"inf\", \"epsilon\":0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from attacks.FGA_Batch import fast_gradient_attack \n",
    "from utils.Visual import drawPlot\n",
    "\n",
    "# load model. \n",
    "#loaded_dict = torch.load(\"/nfs/homedirs/herrmanp/project-4/experiments/notebooks/pascal/first_search_4.pt\")\n",
    "#model = M5PLModule(loaded_dict[\"hparams\"])\n",
    "#model.model.load_state_dict(loaded_dict[\"state_dict\"])\n",
    "\n",
    "# define search space\n",
    "norms = [\"inf\"]\n",
    "epsilons = [1e-100, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1]\n",
    "\n",
    "# run experiment\n",
    "all_attack_reports = []\n",
    "for norm in norms:\n",
    "    current_attack_report = []\n",
    "    for eps in epsilons:\n",
    "        result = model.report(attack=fast_gradient_attack, attack_args = {\"norm\":norm, \"epsilon\":eps})\n",
    "        current_attack_report.append(result)\n",
    "    all_attack_reports.append(current_attack_report)\n",
    "\n",
    "    # visalize results\n",
    "vis_objects = []\n",
    "for i in range(len(norms)):\n",
    "    report_accs = [ res['acc'] for res in all_attack_reports[i] ] \n",
    "    vis_objects.append({\"data\": report_accs, \"color\" : \"rbgycmk\"[i], \"label\": \"Projected Gradient Descent ({} Norm) after Adv Training (300 epochs, L1, eps=[2000, 20000])\".format(norms[i])})\n",
    "    \n",
    "drawPlot(x = epsilons, data = vis_objects, x_label = \"\", y_label = \"\", title = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from utils.Visual import showAudio\n",
    "from torch.utils.data import DataLoader  \n",
    "loaded_dict = torch.load(\"/nfs/homedirs/herrmanp/project-4/experiments/notebooks/pascal/adv_totaly_hig_50epochs.pt\")\n",
    "best_model = M5(loaded_dict[\"hparams\"])\n",
    "best_model.load_state_dict(loaded_dict[\"state_dict\"])\n",
    "best_model.cuda()\n",
    "\n",
    "test_loader = DataLoader(model.dataset[\"val\"], batch_size=1, shuffle=True)\n",
    "\n",
    "showAudio(x)\n",
    "perturbed = model.attack_fn(best_model, x.cuda(), y.cuda(), **{\"norm\":\"inf\", \"epsilon\":0.5})\n",
    "print(perturbed)\n",
    "showAudio(perturbed.cpu().numpy())\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
