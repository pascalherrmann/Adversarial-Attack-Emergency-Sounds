{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:58:10.541732Z",
     "start_time": "2020-06-04T16:57:59.028082Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# json\n",
    "import json\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch import Tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "import librosa\n",
    "from torch_specinv import griffin_lim\n",
    "from torch_specinv.metrics import spectral_convergence as SC\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import youtube_dl\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "\n",
    "import cvxpy as cp\n",
    "import math\n",
    "from torchaudio import functional as AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:58:10.610241Z",
     "start_time": "2020-06-04T16:58:10.545907Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "use_cuda=True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:58:10.654761Z",
     "start_time": "2020-06-04T16:58:10.611451Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FIXED_SAMPLE_RATE = 48000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:57:51.656468Z",
     "start_time": "2020-06-04T16:57:51.524589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from classification.models.DeepRecursiveCNN import DeepRecursiveCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:59:05.982497Z",
     "start_time": "2020-06-04T16:58:18.244495Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_path = \"/nfs/students/summer-term-2020/project-4/data/dataset1/dataset_resampled/\"\n",
    "training = pickle.load(open(pickle_path + \"training.p\",\"rb\"))\n",
    "validation = pickle.load(open(pickle_path + \"validation.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:59:06.417483Z",
     "start_time": "2020-06-04T16:59:05.986943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481489\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "\n",
    "for sample in training:\n",
    "    max_length = max(max_length, sample['data'][0].shape[0])\n",
    "\n",
    "for sample in validation:\n",
    "    max_length = max(max_length, sample['data'][0].shape[0])\n",
    "    \n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:59:06.508847Z",
     "start_time": "2020-06-04T16:59:06.423301Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepareData(data):\n",
    "    zero_padded_data = torch.zeros(max_length)\n",
    "    zero_padded_data[:data.shape[0]] = torch.from_numpy(data)\n",
    "    return zero_padded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:59:32.147540Z",
     "start_time": "2020-06-04T16:59:06.514612Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dataset = [(prepareData(sample['data'][0]), 1)\n",
    "                        if sample['binary_class']=='positive' else (prepareData(sample['data'][0]), 0) \n",
    "                        for sample in training]\n",
    "validation_dataset = [(prepareData(sample['data'][0]), 1)\n",
    "                        if sample['binary_class']=='positive' else (prepareData(sample['data'][0]), 0) \n",
    "                        for sample in validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:24:26.626401Z",
     "start_time": "2020-06-04T16:24:26.454754Z"
    }
   },
   "outputs": [],
   "source": [
    "path_tum_sound = '/nfs/students/summer-term-2020/project-4/yan/tum.wav'\n",
    "tum_sound,sr = librosa.load(path_tum_sound, sr=FIXED_SAMPLE_RATE)\n",
    "padding = int((max_length - len(tum_sound))/2)\n",
    "zero_padded_data = torch.zeros(max_length)\n",
    "zero_padded_data[padding:padding+tum_sound.shape[0]] = torch.from_numpy(tum_sound)\n",
    "tum_sound = zero_padded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:59:32.581608Z",
     "start_time": "2020-06-04T16:59:32.207640Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, epoch=0):\n",
    "    valid_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(valid_loader,0):\n",
    "            samples, labels = [x.cuda() for x in data]\n",
    "            outputs = model(samples)\n",
    "\n",
    "            y_pred.append(torch.max(outputs.data, 1)[1].item())\n",
    "            y_true.append(labels.item())\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "    print('[%d] valid-loss: %.3f' % (epoch + 1, running_loss / (i+1)))\n",
    "            \n",
    "    return reportScore(y_true, y_pred), running_loss / (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:59:32.897579Z",
     "start_time": "2020-06-04T16:59:32.586474Z"
    }
   },
   "outputs": [],
   "source": [
    "def reportScore(y_true, y_pred):\n",
    "    print(\"\\tAccuracy:\\t\" + str(metrics.accuracy_score(y_true,y_pred)))\n",
    "    print(\"\\tPrecision:\\t\" + str(metrics.precision_score(y_true,y_pred)))\n",
    "    print(\"\\tRecall:   \\t\" + str(metrics.recall_score(y_true,y_pred)))\n",
    "    print(\"\\tF1-score:\\t\" + str(metrics.f1_score(y_true,y_pred)))\n",
    "\n",
    "    #tn, fp, fn, tp = metrics.confusion_matrix(y_true,y_pred).ravel()\n",
    "    return metrics.accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T17:00:02.556979Z",
     "start_time": "2020-06-04T17:00:02.139878Z"
    }
   },
   "outputs": [],
   "source": [
    "model_state_dict_path = \"/nfs/students/summer-term-2020/project-4/yan/models/best_model_state_dict.pt\"\n",
    "model = DeepRecursiveCNN()\n",
    "model.load_state_dict(torch.load(model_state_dict_path))\n",
    "model.eval() # important! we don't optimize the model anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T17:00:12.551649Z",
     "start_time": "2020-06-04T17:00:12.207397Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_IncompatibleKeys' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-67f96fad7f04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: '_IncompatibleKeys' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## General framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:29.333016Z",
     "start_time": "2020-06-03T20:18:29.314238Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def testAttack(model, data_loader, attack, epsilon, num_iter=1, early_stopping=-1):\n",
    "    # https://pytorch.org/tutorials/beginner/fgsm_tutorial.html\n",
    "    model.eval().cuda()\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    \n",
    "    success = 0\n",
    "    for i, data in tqdm(list(enumerate(data_loader,0)), position=0):\n",
    "        data, target = [x.cuda() for x in data]\n",
    "\n",
    "        output = model(data)\n",
    "        _, init_pred = torch.max(output.data, 1) # get the index of the max log-probability\n",
    "\n",
    "        if init_pred.item() != target.item():\n",
    "            continue # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "\n",
    "        perturbed_data = attack(model, data, target, epsilon, num_iter)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        \n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 50):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (i, init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            success += 1\n",
    "            if early_stopping > 0:\n",
    "                print(\"Found adversarial example\")\n",
    "                \n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 50:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (i, init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        \n",
    "        if early_stopping > 0 and len(adv_examples) == early_stopping:\n",
    "            return -1, adv_examples\n",
    "        \n",
    "    final_acc = correct/float(len(data_loader))\n",
    "    print(\"Epsilon: {}\\tIterations: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, num_iter, correct, len(data_loader), final_acc))\n",
    "\n",
    "    return final_acc, adv_examples, success, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:29.682580Z",
     "start_time": "2020-06-03T20:18:29.338660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "windowsize = 2048\n",
    "window = torch.hann_window(windowsize)\n",
    "\n",
    "def audio2spec(y):\n",
    "    return torch.stft(y, windowsize, window=window).pow(2).sum(2).sqrt()\n",
    "\n",
    "def drawSpec(mag):\n",
    "    log_S = librosa.power_to_db(mag.numpy(), ref=np.max(mag.numpy()))\n",
    "    plt.figure(figsize=(12,2))\n",
    "    ax = librosa.display.specshow(log_S, sr=FIXED_SAMPLE_RATE, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:29.698120Z",
     "start_time": "2020-06-03T20:18:29.688474Z"
    }
   },
   "outputs": [],
   "source": [
    "## speedup with padding\n",
    "def time_stretch(sample, speedup_rate):\n",
    "    if speedup_rate == 1:\n",
    "        return sample\n",
    "    \n",
    "    n_fft = 2048 # windowsize\n",
    "    hop_length = int(np.floor(n_fft / 4))\n",
    "    \n",
    "    # speedup\n",
    "    stft = torch.stft(sample, n_fft, hop_length=hop_length, window=window).unsqueeze(0)\n",
    "    phase_advance = torch.linspace(0, math.pi * hop_length, stft.shape[1])[..., None]\n",
    "    vocoded = AF.phase_vocoder(stft, rate=speedup_rate, phase_advance=phase_advance)\n",
    "    istft = AF.istft(vocoded, n_fft, hop_length=hop_length, window=window).squeeze()\n",
    "    \n",
    "    max_length = sample.shape[0]\n",
    "\n",
    "    if speedup_rate > 1: \n",
    "        # faster means output is smaller -> padding\n",
    "        pad_l = int((max_length - istft.shape[0])/2)\n",
    "        pad_r = max_length - (pad_l + istft.shape[0])\n",
    "        return F.pad(istft, (pad_l, pad_r))\n",
    "    else:\n",
    "        # slower means longer -> chopping of\n",
    "        low = int((istft.shape[0] - max_length)/2)\n",
    "        return istft[low:low+max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T21:37:48.441762Z",
     "start_time": "2020-06-03T21:37:48.431567Z"
    }
   },
   "outputs": [],
   "source": [
    "def speed_attack(model, x, y, epsilon, num_iter=1):\n",
    "    a=0.9\n",
    "    b=1.1\n",
    "    rate_search_range = torch.arange(a, b, float(1)/num_iter)\n",
    "    losses = []\n",
    "    stretched_inputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for rate in rate_search_range:\n",
    "            stretched = time_stretch(x.squeeze().cpu(), rate).cuda().unsqueeze(0)\n",
    "            stretched_inputs.append(stretched)\n",
    "            losses.append(F.nll_loss(model(stretched), y))\n",
    "            \n",
    "    best_rate = torch.stack(losses).argmax().item()\n",
    "    return stretched_inputs[best_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:12:29.637748Z",
     "start_time": "2020-06-04T16:12:29.630957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f99c01cbc70>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils.data.DataLoader(audioset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T21:37:35.036863Z",
     "start_time": "2020-06-03T20:58:35.871215Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 732/1687 [38:56<50:48,  3.19s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-ca8c7045c851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestAttack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeed_attack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-f285b98ca888>\u001b[0m in \u001b[0;36mtestAttack\u001b[0;34m(model, data_loader, attack, epsilon, num_iter, early_stopping)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mcontinue\u001b[0m \u001b[0;31m# If the initial prediction is wrong, dont bother attacking, just move on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mperturbed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Re-classify the perturbed image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-c3ed6ec1d112>\u001b[0m in \u001b[0;36mspeed_attack\u001b[0;34m(model, x, y, epsilon, num_iter)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrate_search_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mstretched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_stretch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mstretched_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstretched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstretched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-7721a2928bed>\u001b[0m in \u001b[0;36mtime_stretch\u001b[0;34m(sample, speedup_rate)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mphase_advance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mvocoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase_vocoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspeedup_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_advance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mphase_advance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mistft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mistft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/students/summer-term-2020/project-4/yan/.conda/envs/cnn_project/lib/python3.8/site-packages/torchaudio/functional.py\u001b[0m in \u001b[0;36mphase_vocoder\u001b[0;34m(complex_specgrams, rate, phase_advance)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0mangle_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_specgrams_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m     \u001b[0mnorm_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_specgrams_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m     \u001b[0mnorm_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_specgrams_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/students/summer-term-2020/project-4/yan/.conda/envs/cnn_project/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "acc, ex = testAttack(model, valid_loader, speed_attack, -1, num_iter=20, early_stopping=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:57:31.853084Z",
     "start_time": "2020-06-03T20:57:31.837392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 1, 0, array([0., 0., 0., ..., 0., 0., 0.], dtype=float32))]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:57:38.020145Z",
     "start_time": "2020-06-03T20:57:38.010096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found good adversarial sample: \n",
      "\tSample id: 7\n"
     ]
    }
   ],
   "source": [
    "eps = -1\n",
    "adversarial_samples = {}\n",
    "\n",
    "for sample in ex:\n",
    "    if sample[1] == 1: # ie. previously correctly classified as EM\n",
    "        print(\"found good adversarial sample: \")\n",
    "        example_id = sample[0]\n",
    "        print(\"\\tSample id: \" + str(example_id))\n",
    "        adversarial_samples.update({example_id : sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:57:43.552647Z",
     "start_time": "2020-06-03T20:57:43.449093Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = adversarial_samples[7] #random.sample(list(adversarial_samples.values()),1)[0]\n",
    "print(sample[0])\n",
    "original = validation_dataset[sample[0]][0]\n",
    "adversarial = sample[-1]\n",
    "\n",
    "ipd.display(ipd.Audio(original,    rate=FIXED_SAMPLE_RATE, normalize=False))\n",
    "ipd.display(ipd.Audio(adversarial, rate=FIXED_SAMPLE_RATE, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.942585Z",
     "start_time": "2020-06-03T20:16:03.303Z"
    }
   },
   "outputs": [],
   "source": [
    "raise Exception(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.947328Z",
     "start_time": "2020-06-03T20:16:03.313Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Interpolation attack: \n",
    "        - take gradient wrt. the interpolation parameters a,b \n",
    "        \n",
    "    Parameters:\n",
    "        - tum_sound: sound to be inserted\n",
    "        - epsilon: gradient step size\n",
    "        - num_iterations: PGD iterations\n",
    "        - clamping parameters for a, b (4 in total): define the max/min of interpolation volume\n",
    "'''\n",
    "def insertion_attack(model, x, y, epsilon, num_iter=1):\n",
    "    global tum_sound\n",
    "    \n",
    "    x = x.clone().detach()\n",
    "    a = torch.tensor(1.0).cuda() # original sound volume\n",
    "    b = torch.tensor(1.0).cuda() # inserted sound volume\n",
    "    tum_sound = tum_sound.cuda()\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        a.requires_grad_()\n",
    "        b.requires_grad_()\n",
    "        \n",
    "        loss = F.nll_loss(model(a * x + b * tum_sound), y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        a = (a + epsilon * a.grad.data).clamp(0.8,1).detach()\n",
    "        b = (b + epsilon * b.grad.data).clamp(0.05,0.1).detach()\n",
    "\n",
    "    return (a * x + b * tum_sound).clamp(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.952118Z",
     "start_time": "2020-06-03T20:16:03.318Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run test for each epsilon\n",
    "epsilons = [.3]\n",
    "\n",
    "for eps in epsilons:\n",
    "    acc, ex = testAttack(model, valid_loader, insertion_attack, eps, num_iter=10)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.956145Z",
     "start_time": "2020-06-03T20:16:03.324Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Interpolation attack: \n",
    "        - take gradient wrt. the interpolation parameters a,b \n",
    "        \n",
    "    Parameters:\n",
    "        - tum_sound: sound to be inserted\n",
    "        - epsilon: gradient step size\n",
    "        - num_iterations: PGD iterations\n",
    "        - clamping parameters for a, b (4 in total): define the max/min of interpolation volume\n",
    "'''\n",
    "def insertion_attack(model, x, y, epsilon, num_iter=1):\n",
    "    global tum_sound\n",
    "    \n",
    "    x = x.clone().detach()\n",
    "    a = torch.tensor(1.0).cuda() # original sound volume\n",
    "    b = torch.tensor(1.0).cuda() # inserted sound volume\n",
    "    tum_sound = tum_sound.cuda()\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        a.requires_grad_()\n",
    "        b.requires_grad_()\n",
    "        \n",
    "        loss = F.nll_loss(model(a * x + b * tum_sound), y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        a = (a + epsilon * a.grad.data).clamp(0.8,1).detach()\n",
    "        b = (b + epsilon * b.grad.data).clamp(0.05,0.1).detach()\n",
    "\n",
    "    return (a * x + b * tum_sound).clamp(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.961935Z",
     "start_time": "2020-06-03T20:16:03.329Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run test for each epsilon\n",
    "epsilons = [.3]\n",
    "\n",
    "for eps in epsilons:\n",
    "    acc, ex = testAttack(model, valid_loader, insertion_attack, eps, num_iter=10)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Epsilon: 0.3\tIterations: 10\tTest Accuracy = 1489 / 1687 = 0.8826318909306461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.965140Z",
     "start_time": "2020-06-03T20:16:03.334Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eps = -1\n",
    "adversarial_samples = {}\n",
    "\n",
    "for sample in examples[eps]:\n",
    "    if sample[1] == 1: # ie. previously correctly classified as EM\n",
    "        print(\"found good adversarial sample: \")\n",
    "        example_id = sample[0]\n",
    "        print(\"\\tSample id: \" + str(example_id))\n",
    "        adversarial_samples.update({example_id : sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.966880Z",
     "start_time": "2020-06-03T20:16:03.339Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = adversarial_samples[1149] #random.sample(list(adversarial_samples.values()),1)[0]\n",
    "print(sample[0])\n",
    "original = validation_dataset[sample[0]][0]\n",
    "adversarial = sample[-1]\n",
    "\n",
    "ipd.display(ipd.Audio(original,    rate=FIXED_SAMPLE_RATE, normalize=False))\n",
    "ipd.display(ipd.Audio(adversarial, rate=FIXED_SAMPLE_RATE, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Volume attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.969421Z",
     "start_time": "2020-06-03T20:16:03.345Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def volume_attack(model, x, y, epsilon, num_iter=1):\n",
    "    x = x.clone().detach()\n",
    "    a = torch.tensor(1.0).cuda()\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        a.requires_grad_()\n",
    "        \n",
    "        loss = F.nll_loss(model(a * x), y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        a = (a + epsilon * a.grad.data).clamp(0.2,2).detach()\n",
    "    \n",
    "    return (a * x).clamp(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.971643Z",
     "start_time": "2020-06-03T20:16:03.350Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run test for each epsilon\n",
    "epsilons = [.3]\n",
    "\n",
    "for eps in epsilons:\n",
    "    acc, ex, _, _ = testAttack(model, valid_loader, volume_attack, eps, num_iter=10)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T14:38:44.456249Z",
     "start_time": "2020-05-24T14:38:44.448821Z"
    },
    "hidden": true
   },
   "source": [
    "    Epsilon: 0.3\tIterations: 10\tTest Accuracy = 1387 / 1687 = 0.8221695317131001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.974624Z",
     "start_time": "2020-06-03T20:16:03.356Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eps = -1\n",
    "adversarial_samples = {}\n",
    "\n",
    "for sample in examples[eps]:\n",
    "    if sample[1] == 1: # ie. previously correctly classified as EM\n",
    "        print(\"found good adversarial sample: \")\n",
    "        example_id = sample[0]\n",
    "        print(\"\\tSample id: \" + str(example_id))\n",
    "        adversarial_samples.update({example_id : sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.986647Z",
     "start_time": "2020-06-03T20:16:03.362Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = random.sample(list(adversarial_samples.values()),1)[0]\n",
    "print(sample[0])\n",
    "original = validation_dataset[sample[0]][0]\n",
    "adversarial = sample[-1]\n",
    "\n",
    "ipd.display(ipd.Audio(original,    rate=FIXED_SAMPLE_RATE, normalize=False))\n",
    "ipd.display(ipd.Audio(adversarial, rate=FIXED_SAMPLE_RATE, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simple PGD (SPGD) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.987821Z",
     "start_time": "2020-06-03T20:16:03.367Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def spgd_attack(model, x, y, epsilon, num_iter=1):\n",
    "    \n",
    "    perturbed_sample = x\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        perturbed_sample = perturbed_sample.clone().detach().requires_grad_(True).cuda()\n",
    "        loss = F.nll_loss(model(perturbed_sample), y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        perturbed_sample = perturbed_sample + epsilon * perturbed_sample.grad.data\n",
    "        perturbed_sample = (perturbed_sample).clamp(-1, 1) # simple clamp projection\n",
    "\n",
    "    return perturbed_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.988957Z",
     "start_time": "2020-06-03T20:16:03.371Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run test for each epsilon\n",
    "epsilons = [.05, 0.1]\n",
    "\n",
    "for eps in epsilons:\n",
    "    print(eps)\n",
    "    acc, ex = testAttack(model, valid_loader, spgd_attack, eps, num_iter=20)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "     30 min for 20 iterations each\n",
    "     \n",
    "     Epsilon: 0.01\tIterations: 20\tTest Accuracy = 1466 / 1687 = 0.8689982216953172\n",
    "     Epsilon: 0.05\tIterations: 20\tTest Accuracy = 1367 / 1687 = 0.8103141671606402\n",
    "     Epsilon: 0.1\tIterations: 20\tTest Accuracy = 1267 / 1687 = 0.7510373443983402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.990168Z",
     "start_time": "2020-06-03T20:16:03.377Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eps = -1\n",
    "adversarial_samples = {}\n",
    "\n",
    "for sample in examples[eps]:\n",
    "    if sample[1] == 1: # ie. previously correctly classified as EM\n",
    "        print(\"found good adversarial sample: \")\n",
    "        example_id = sample[0]\n",
    "        print(\"\\tSample id: \" + str(example_id))\n",
    "        adversarial_samples.update({example_id : sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.991255Z",
     "start_time": "2020-06-03T20:16:03.382Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = adversarial_samples[9] #random.sample(list(adversarial_samples.values()),1)[0]\n",
    "print(sample[0])\n",
    "original = validation_dataset[sample[0]][0]\n",
    "adversarial = sample[-1]\n",
    "\n",
    "ipd.display(ipd.Audio(original,    rate=FIXED_SAMPLE_RATE, normalize=False))\n",
    "ipd.display(ipd.Audio(adversarial, rate=FIXED_SAMPLE_RATE, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## FGSM method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.992476Z",
     "start_time": "2020-06-03T20:16:03.387Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fgsm_attack(model, x, y, epsilon, num_iter=1):\n",
    "    x.requires_grad = True\n",
    "    loss = F.nll_loss(model(x), y)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    perturbed_sample = x + epsilon * x.grad.data.sign()\n",
    "    return perturbed_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.993890Z",
     "start_time": "2020-06-03T20:16:03.392Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run test for each epsilon\n",
    "epsilons = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1] \n",
    "_, _, _, TPTN = testAttack(model, valid_loader, fgsm_attack, epsilon=0, num_iter=1)\n",
    "\n",
    "print(\"Start attack\")\n",
    "for eps in epsilons:\n",
    "    acc, ex, success, _ = testAttack(model, valid_loader, fgsm_attack, eps, num_iter=1)\n",
    "    print(\"\\tSuccess Rate: {} / {} = {}\".format(success, TPTN, success/float(TPTN)))\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    Epsilon: 0\tIterations: 1\tTest Accuracy = 1503 / 1687 = 0.8909306461173682\n",
    "    Epsilon: 0.001\tIterations: 1\tTest Accuracy = 1431 / 1687 = 0.8482513337285121\n",
    "        Success Rate: 72 / 1503 = 0.04790419161676647\n",
    "    Epsilon: 0.002\tIterations: 1\tTest Accuracy = 1357 / 1687 = 0.8043864848844102\n",
    "        Success Rate: 146 / 1503 = 0.09713905522288756\n",
    "    Epsilon: 0.005\tIterations: 1\tTest Accuracy = 1104 / 1687 = 0.6544161232957914\n",
    "        Success Rate: 399 / 1503 = 0.2654690618762475\n",
    "    Epsilon: 0.01\tIterations: 1\tTest Accuracy = 891 / 1687 = 0.5281564908120925\n",
    "        Success Rate: 612 / 1503 = 0.40718562874251496\n",
    "    Epsilon: 0.02\tIterations: 1\tTest Accuracy = 726 / 1687 = 0.4303497332542976\n",
    "        Success Rate: 777 / 1503 = 0.5169660678642715\n",
    "    Epsilon: 0.05\tIterations: 1\tTest Accuracy = 863 / 1687 = 0.5115589804386484\n",
    "        Success Rate: 640 / 1503 = 0.4258150365934797\n",
    "    Epsilon: 0.1\tIterations: 1\tTest Accuracy = 982 / 1687 = 0.5820983995257855\n",
    "        Success Rate: 521 / 1503 = 0.3466400532268796\n",
    "    Epsilon: 0.2\tIterations: 1\tTest Accuracy = 882 / 1687 = 0.5228215767634855\n",
    "        Success Rate: 621 / 1503 = 0.41317365269461076\n",
    "    Epsilon: 0.5\tIterations: 1\tTest Accuracy = 793 / 1687 = 0.4700652045050385\n",
    "        Success Rate: 710 / 1503 = 0.47238855622089154\n",
    "    Epsilon: 1\tIterations: 1\tTest Accuracy = 762 / 1687 = 0.45168938944872555\n",
    "        Success Rate: 741 / 1503 = 0.4930139720558882"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "72, 146, 399, 612, 777, 640, 521, 621, 710, 741"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.995344Z",
     "start_time": "2020-06-03T20:16:03.398Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eps = -1\n",
    "adversarial_samples = {}\n",
    "\n",
    "for sample in examples[eps]:\n",
    "    if sample[1] == 1: # ie. previously correctly classified as EM\n",
    "        print(\"found good adversarial sample: \")\n",
    "        example_id = sample[0]\n",
    "        print(\"\\tSample id: \" + str(example_id))\n",
    "        adversarial_samples.update({example_id : sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.998619Z",
     "start_time": "2020-06-03T20:16:03.406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = random.sample(list(adversarial_samples.values()),1)[0]\n",
    "print(sample[0])\n",
    "original = validation_dataset[sample[0]][0]\n",
    "adversarial = sample[-1]\n",
    "\n",
    "ipd.display(ipd.Audio(original,    rate=FIXED_SAMPLE_RATE))\n",
    "ipd.display(ipd.Audio(adversarial, rate=FIXED_SAMPLE_RATE, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:38.003302Z",
     "start_time": "2020-06-03T20:16:03.414Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "drawSpec(audio2spec(torch.tensor(original)))\n",
    "drawSpec(audio2spec(torch.tensor(adversarial)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:38.004458Z",
     "start_time": "2020-06-03T20:16:03.421Z"
    }
   },
   "outputs": [],
   "source": [
    "## exec break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
