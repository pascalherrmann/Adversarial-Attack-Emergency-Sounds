{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:58:10.541732Z",
     "start_time": "2020-06-04T16:57:59.028082Z"
    }
   },
   "outputs": [],
   "source": [
    "# json\n",
    "import json\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch import Tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "import librosa\n",
    "from torch_specinv import griffin_lim\n",
    "from torch_specinv.metrics import spectral_convergence as SC\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import youtube_dl\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "\n",
    "import cvxpy as cp\n",
    "import math\n",
    "from torchaudio import functional as AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:58:10.610241Z",
     "start_time": "2020-06-04T16:58:10.545907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "use_cuda=True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:58:10.654761Z",
     "start_time": "2020-06-04T16:58:10.611451Z"
    }
   },
   "outputs": [],
   "source": [
    "FIXED_SAMPLE_RATE = 48000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T17:04:32.792854Z",
     "start_time": "2020-06-04T17:04:32.389726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from classification.models.DeepRecursiveCNN import DeepRecursiveCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:59:05.982497Z",
     "start_time": "2020-06-04T16:58:18.244495Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_path = \"/nfs/students/summer-term-2020/project-4/data/dataset1/dataset_resampled/\"\n",
    "training = pickle.load(open(pickle_path + \"training.p\",\"rb\"))\n",
    "validation = pickle.load(open(pickle_path + \"validation.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:59:06.417483Z",
     "start_time": "2020-06-04T16:59:05.986943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481489\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "\n",
    "for sample in training:\n",
    "    max_length = max(max_length, sample['data'][0].shape[0])\n",
    "\n",
    "for sample in validation:\n",
    "    max_length = max(max_length, sample['data'][0].shape[0])\n",
    "    \n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:59:06.508847Z",
     "start_time": "2020-06-04T16:59:06.423301Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepareData(data):\n",
    "    zero_padded_data = torch.zeros(max_length)\n",
    "    zero_padded_data[:data.shape[0]] = torch.from_numpy(data)\n",
    "    return zero_padded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:59:32.147540Z",
     "start_time": "2020-06-04T16:59:06.514612Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dataset = [(prepareData(sample['data'][0]), 1)\n",
    "                        if sample['binary_class']=='positive' else (prepareData(sample['data'][0]), 0) \n",
    "                        for sample in training]\n",
    "validation_dataset = [(prepareData(sample['data'][0]), 1)\n",
    "                        if sample['binary_class']=='positive' else (prepareData(sample['data'][0]), 0) \n",
    "                        for sample in validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T19:30:11.643196Z",
     "start_time": "2020-06-04T19:30:11.323879Z"
    }
   },
   "outputs": [],
   "source": [
    "model_state_dict_path = \"/nfs/students/summer-term-2020/project-4/yan/models/best_model_state_dict.pt\"\n",
    "model = DeepRecursiveCNN()\n",
    "model.load_state_dict(torch.load(model_state_dict_path))\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:29.698120Z",
     "start_time": "2020-06-03T20:18:29.688474Z"
    }
   },
   "outputs": [],
   "source": [
    "## speedup with padding\n",
    "def time_stretch(sample, speedup_rate):\n",
    "    if speedup_rate == 1:\n",
    "        return sample\n",
    "    \n",
    "    n_fft = 2048 # windowsize\n",
    "    hop_length = int(np.floor(n_fft / 4))\n",
    "    \n",
    "    # speedup\n",
    "    stft = torch.stft(sample, n_fft, hop_length=hop_length, window=window).unsqueeze(0)\n",
    "    phase_advance = torch.linspace(0, math.pi * hop_length, stft.shape[1])[..., None]\n",
    "    vocoded = AF.phase_vocoder(stft, rate=speedup_rate, phase_advance=phase_advance)\n",
    "    istft = AF.istft(vocoded, n_fft, hop_length=hop_length, window=window).squeeze()\n",
    "    \n",
    "    max_length = sample.shape[0]\n",
    "\n",
    "    if speedup_rate > 1: \n",
    "        # faster means output is smaller -> padding\n",
    "        pad_l = int((max_length - istft.shape[0])/2)\n",
    "        pad_r = max_length - (pad_l + istft.shape[0])\n",
    "        return F.pad(istft, (pad_l, pad_r))\n",
    "    else:\n",
    "        # slower means longer -> chopping of\n",
    "        low = int((istft.shape[0] - max_length)/2)\n",
    "        return istft[low:low+max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T21:37:48.441762Z",
     "start_time": "2020-06-03T21:37:48.431567Z"
    }
   },
   "outputs": [],
   "source": [
    "def speed_attack(model, x, y, epsilon, num_iter=1):\n",
    "    a=0.9\n",
    "    b=1.1\n",
    "    rate_search_range = torch.arange(a, b, float(1)/num_iter)\n",
    "    losses = []\n",
    "    stretched_inputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for rate in rate_search_range:\n",
    "            stretched = time_stretch(x.squeeze().cpu(), rate).cuda().unsqueeze(0)\n",
    "            stretched_inputs.append(stretched)\n",
    "            losses.append(F.nll_loss(model(stretched), y))\n",
    "            \n",
    "    best_rate = torch.stack(losses).argmax().item()\n",
    "    return stretched_inputs[best_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:12:29.637748Z",
     "start_time": "2020-06-04T16:12:29.630957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f99c01cbc70>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils.data.DataLoader(audioset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T21:37:35.036863Z",
     "start_time": "2020-06-03T20:58:35.871215Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 732/1687 [38:56<50:48,  3.19s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-ca8c7045c851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestAttack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeed_attack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-f285b98ca888>\u001b[0m in \u001b[0;36mtestAttack\u001b[0;34m(model, data_loader, attack, epsilon, num_iter, early_stopping)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mcontinue\u001b[0m \u001b[0;31m# If the initial prediction is wrong, dont bother attacking, just move on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mperturbed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Re-classify the perturbed image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-c3ed6ec1d112>\u001b[0m in \u001b[0;36mspeed_attack\u001b[0;34m(model, x, y, epsilon, num_iter)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrate_search_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mstretched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_stretch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mstretched_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstretched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstretched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-7721a2928bed>\u001b[0m in \u001b[0;36mtime_stretch\u001b[0;34m(sample, speedup_rate)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mphase_advance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mvocoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase_vocoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspeedup_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_advance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mphase_advance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mistft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mistft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/students/summer-term-2020/project-4/yan/.conda/envs/cnn_project/lib/python3.8/site-packages/torchaudio/functional.py\u001b[0m in \u001b[0;36mphase_vocoder\u001b[0;34m(complex_specgrams, rate, phase_advance)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0mangle_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_specgrams_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m     \u001b[0mnorm_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_specgrams_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m     \u001b[0mnorm_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_specgrams_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/students/summer-term-2020/project-4/yan/.conda/envs/cnn_project/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "acc, ex = testAttack(model, valid_loader, speed_attack, -1, num_iter=20, early_stopping=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:57:38.020145Z",
     "start_time": "2020-06-03T20:57:38.010096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found good adversarial sample: \n",
      "\tSample id: 7\n"
     ]
    }
   ],
   "source": [
    "eps = -1\n",
    "adversarial_samples = {}\n",
    "\n",
    "for sample in ex:\n",
    "    if sample[1] == 1: # ie. previously correctly classified as EM\n",
    "        print(\"found good adversarial sample: \")\n",
    "        example_id = sample[0]\n",
    "        print(\"\\tSample id: \" + str(example_id))\n",
    "        adversarial_samples.update({example_id : sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:57:43.552647Z",
     "start_time": "2020-06-03T20:57:43.449093Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = adversarial_samples[7] #random.sample(list(adversarial_samples.values()),1)[0]\n",
    "print(sample[0])\n",
    "original = validation_dataset[sample[0]][0]\n",
    "adversarial = sample[-1]\n",
    "\n",
    "ipd.display(ipd.Audio(original,    rate=FIXED_SAMPLE_RATE, normalize=False))\n",
    "ipd.display(ipd.Audio(adversarial, rate=FIXED_SAMPLE_RATE, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T20:18:37.942585Z",
     "start_time": "2020-06-03T20:16:03.303Z"
    }
   },
   "outputs": [],
   "source": [
    "raise Exception(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T20:34:22.450111Z",
     "start_time": "2020-06-04T20:34:19.924833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 9, done.\u001b[K\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 5 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (5/5), done.\n",
      "From gitlab.lrz.de:ml-lab-summer-2020/project-4\n",
      "   f477cd8..8dba3af  develop_yan -> origin/develop_yan\n",
      "Updating f477cd8..8dba3af\n",
      "Fast-forward\n",
      " src/attacks/interpolation.py | 1 \u001b[32m+\u001b[m\n",
      " 1 file changed, 1 insertion(+)\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T20:32:36.103205Z",
     "start_time": "2020-06-04T20:32:35.700443Z"
    }
   },
   "outputs": [],
   "source": [
    "path_tum_sound = '/nfs/students/summer-term-2020/project-4/yan/tum.wav'\n",
    "tum_sound,sr = librosa.load(path_tum_sound, sr=FIXED_SAMPLE_RATE)\n",
    "padding = int((max_length - len(tum_sound))/2)\n",
    "zero_padded_data = torch.zeros(max_length)\n",
    "zero_padded_data[padding:padding+tum_sound.shape[0]] = torch.from_numpy(tum_sound)\n",
    "tum_sound = zero_padded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T20:36:31.560915Z",
     "start_time": "2020-06-04T20:34:25.924385Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 74/1687 [02:04<45:03,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from attacks.interpolation import InterpolationAttack\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "attack_parameters = {'epsilon': 0.2, 'num_iter': 30, 'overlay_sound': tum_sound}\n",
    "\n",
    "ia = InterpolationAttack(model, valid_loader, attack_parameters, early_stopping=1)\n",
    "ia.attack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T20:37:37.917890Z",
     "start_time": "2020-06-04T20:37:37.602498Z"
    }
   },
   "outputs": [],
   "source": [
    "# ia.showAdversarialExample(sr=FIXED_SAMPLE_RATE, target_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T20:36:31.960045Z",
     "start_time": "2020-06-04T20:36:31.901004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack-Parameters:\t{'epsilon': 0.2, 'num_iter': 30, 'overlay_sound': tensor([0., 0., 0.,  ..., 0., 0., 0.])}\n",
      "Early stopping: \tTrue (1)\n",
      "\n",
      "Successfully attacked:\t1\n",
      "Total attacked: \t67\n",
      "Total processed:\t75\n",
      "\n",
      "Success-Rate: \t\t0.01\n",
      "Perturbed Accurracy: \t0.88\n"
     ]
    }
   ],
   "source": [
    "ia.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Volume attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T20:33:13.923892Z",
     "start_time": "2020-06-04T20:32:56.992883Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/1687 [00:14<58:05,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from attacks.volume import VolumeAttack\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "attack_parameters = {'epsilon': 0.2, 'num_iter': 30}\n",
    "\n",
    "vol = VolumeAttack(model, valid_loader, attack_parameters, early_stopping=1)\n",
    "vol.attack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T20:22:25.973061Z",
     "start_time": "2020-06-04T20:22:25.657473Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# vol.showAdversarialExample(sr=FIXED_SAMPLE_RATE, target_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T20:22:30.868960Z",
     "start_time": "2020-06-04T20:22:30.818977Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack-Parameters:\t{'epsilon': 0.2, 'num_iter': 30}\n",
      "Early stopping: \tTrue (1)\n",
      "\n",
      "Successfully attacked:\t1\n",
      "Total attacked: \t8\n",
      "Total processed:\t8\n",
      "\n",
      "Success-Rate: \t\t0.12\n",
      "Perturbed Accurracy: \t0.88\n"
     ]
    }
   ],
   "source": [
    "vol.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T19:56:22.939764Z",
     "start_time": "2020-06-04T19:56:16.326228Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 53/1687 [00:05<02:35, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from attacks.fgsm import FGSM\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "attack_parameters = {'epsilon': 0.2}\n",
    "\n",
    "fgsm = FGSM(model, valid_loader, attack_parameters, early_stopping=20)\n",
    "fgsm.attack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fgsm.showAdversarialExample(sr=FIXED_SAMPLE_RATE, target_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T19:56:30.255109Z",
     "start_time": "2020-06-04T19:56:30.111146Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack-Parameters:\t{'epsilon': 0.2}\n",
      "Early stopping: \tTrue (20)\n",
      "\n",
      "Successfully attacked:\t20\n",
      "Total attacked: \t49\n",
      "Total processed:\t54\n",
      "\n",
      "Success-Rate: \t\t0.41\n",
      "Perturbed Accurracy: \t0.54\n"
     ]
    }
   ],
   "source": [
    "fgsm.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T19:47:46.082401Z",
     "start_time": "2020-06-04T19:46:34.043637Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 40/1687 [01:09<47:23,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from attacks.pgd import PGD\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "attack_parameters = {'epsilon': 0.5, 'num_iter': 30}\n",
    "\n",
    "pgd = PGD(model, valid_loader, attack_parameters, early_stopping=20)\n",
    "pgd.attack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pgd.showAdversarialExample(sr=FIXED_SAMPLE_RATE, target_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T19:48:07.908980Z",
     "start_time": "2020-06-04T19:48:07.457106Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack-Parameters:\t{'epsilon': 0.5, 'num_iter': 30}\n",
      "Early stopping: \tTrue (20)\n",
      "\n",
      "Successfully attacked:\t20\n",
      "Total attacked: \t37\n",
      "Total processed:\t41\n",
      "\n",
      "Success-Rate: \t\t0.54\n",
      "Perturbed Accurracy: \t0.41\n"
     ]
    }
   ],
   "source": [
    "pgd.report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
