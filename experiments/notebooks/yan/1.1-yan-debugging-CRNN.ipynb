{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T08:36:30.023313Z",
     "start_time": "2020-07-03T08:36:14.784376Z"
    }
   },
   "outputs": [],
   "source": [
    "# json\n",
    "import json\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T08:36:31.594664Z",
     "start_time": "2020-07-03T08:36:30.027470Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from torch_specinv import griffin_lim\n",
    "from torch_specinv.metrics import spectral_convergence as SC\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T08:36:31.607580Z",
     "start_time": "2020-07-03T08:36:31.601956Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T09:25:25.707625Z",
     "start_time": "2020-07-03T09:25:25.653973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "use_cuda=True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T09:25:26.472931Z",
     "start_time": "2020-07-03T09:25:26.463297Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T09:17:27.517750Z",
     "start_time": "2020-06-09T09:16:59.275267Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.audioset import Audioset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "audio_set_tr = Audioset(split_mode='training', fixed_padding=True)\n",
    "audio_set_val = Audioset(split_mode='validation', fixed_padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T09:49:10.168058Z",
     "start_time": "2020-06-09T09:49:10.160029Z"
    }
   },
   "outputs": [],
   "source": [
    "def reportScore(y_true, y_pred):\n",
    "    print(\"\\tAccuracy:\\t\" + str(metrics.accuracy_score(y_true,y_pred)))\n",
    "    print(\"\\tPrecision:\\t\" + str(metrics.precision_score(y_true,y_pred)))\n",
    "    print(\"\\tRecall:   \\t\" + str(metrics.recall_score(y_true,y_pred)))\n",
    "    print(\"\\tF1-score:\\t\" + str(metrics.f1_score(y_true,y_pred)))\n",
    "    #tn, fp, fn, tp = metrics.confusion_matrix(y_true,y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T10:44:58.499157Z",
     "start_time": "2020-06-09T10:44:58.489915Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model):\n",
    "    valid_loader = DataLoader(audio_set_val, batch_size=1)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(valid_loader):\n",
    "            data = [item.cuda() for item in data] # move to gpu\n",
    "            inputs, labels = data[:2], data[-1]\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            y_pred.append(torch.max(outputs.data, 1)[1].item())\n",
    "            y_true.append(labels.item())\n",
    "            \n",
    "    reportScore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T09:29:50.690988Z",
     "start_time": "2020-07-03T09:29:50.662641Z"
    }
   },
   "outputs": [],
   "source": [
    "# audio.py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchaudio.transforms import Spectrogram, MelSpectrogram , ComplexNorm\n",
    "from torchaudio.transforms import TimeStretch, AmplitudeToDB \n",
    "from torch.distributions import Uniform\n",
    "\n",
    "def _num_stft_bins(lengths, fft_length, hop_length, pad):\n",
    "    return (lengths + 2 * pad - fft_length + hop_length) // hop_length\n",
    "\n",
    "class MelspectrogramStretch(MelSpectrogram):\n",
    "\n",
    "    def __init__(self, hop_length=None, \n",
    "                       sample_rate=48000, \n",
    "                       num_mels=128, \n",
    "                       fft_length=2048, \n",
    "                       norm='whiten', \n",
    "                       stretch_param=[0.4, 0.4]):\n",
    "\n",
    "        super(MelspectrogramStretch, self).__init__(sample_rate=sample_rate, \n",
    "                                                    n_fft=fft_length, \n",
    "                                                    hop_length=hop_length, \n",
    "                                                    n_mels=num_mels)\n",
    "\n",
    "        self.stft = Spectrogram(n_fft=self.n_fft, win_length=self.win_length,\n",
    "                                       hop_length=self.hop_length, pad=self.pad, \n",
    "                                       power=None, normalized=False)\n",
    "\n",
    "        # Augmentation\n",
    "        self.prob = stretch_param[0]\n",
    "        self.random_stretch = RandomTimeStretch(stretch_param[1], \n",
    "                                                self.hop_length, \n",
    "                                                self.n_fft//2+1, \n",
    "                                                fixed_rate=None)\n",
    "        \n",
    "        # Normalization (pot spec processing)\n",
    "        self.complex_norm = ComplexNorm(power=2.)\n",
    "        self.norm = SpecNormalization(norm)\n",
    "\n",
    "    def forward(self, x, lengths=None):\n",
    "        x = self.stft(x)\n",
    "\n",
    "        if lengths is not None:\n",
    "            lengths = _num_stft_bins(lengths, self.n_fft, self.hop_length, self.n_fft//2)\n",
    "            lengths = lengths.long()\n",
    "        \n",
    "        if torch.rand(1)[0] <= self.prob and self.training:\n",
    "            # Stretch spectrogram in time using Phase Vocoder\n",
    "            x, rate = self.random_stretch(x)\n",
    "            # Modify the rate accordingly\n",
    "            lengths = (lengths.float()/rate).long()+1\n",
    "        \n",
    "        x = self.complex_norm(x)\n",
    "        x = self.mel_scale(x)\n",
    "\n",
    "        # Normalize melspectrogram\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if lengths is not None:\n",
    "            return x, lengths        \n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'\n",
    "\n",
    "\n",
    "class RandomTimeStretch(TimeStretch):\n",
    "\n",
    "    def __init__(self, max_perc, hop_length=None, n_freq=201, fixed_rate=None):\n",
    "\n",
    "        super(RandomTimeStretch, self).__init__(hop_length, n_freq, fixed_rate)\n",
    "        self._dist = Uniform(1.-max_perc, 1+max_perc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        rate = self._dist.sample().item()\n",
    "        return super(RandomTimeStretch, self).forward(x, rate), rate\n",
    "\n",
    "\n",
    "class SpecNormalization(nn.Module):\n",
    "\n",
    "    def __init__(self, norm_type, top_db=80.0):\n",
    "\n",
    "        super(SpecNormalization, self).__init__()\n",
    "\n",
    "        if 'db' == norm_type:\n",
    "            self._norm = AmplitudeToDB(stype='power', top_db=top_db)\n",
    "        elif 'whiten' == norm_type:\n",
    "            self._norm = lambda x: self.z_transform(x)\n",
    "        else:\n",
    "            self._norm = lambda x: x\n",
    "        \n",
    "    \n",
    "    def z_transform(self, x):\n",
    "        # Independent mean, std per batch\n",
    "        non_batch_inds = [1, 2, 3]\n",
    "        mean = x.mean(non_batch_inds, keepdim=True)\n",
    "        std = x.std(non_batch_inds, keepdim=True)\n",
    "        x = (x - mean)/std \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T09:29:55.063345Z",
     "start_time": "2020-07-03T09:29:55.057487Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss.py\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def nll_loss(output, target):\n",
    "    # loss for log_softmax\n",
    "    return F.nll_loss(output, target)\n",
    "\n",
    "def cross_entropy(output, target):\n",
    "    return F.cross_entropy(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T09:29:57.937592Z",
     "start_time": "2020-07-03T09:29:57.925230Z"
    }
   },
   "outputs": [],
   "source": [
    "# base_model.py\n",
    "import logging\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for all models\n",
    "    \"\"\"\n",
    "    def __init__(self, config=''):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.config = config\n",
    "        self.classes = None\n",
    "        \n",
    "    def forward(self, *input):\n",
    "        \"\"\"\n",
    "        Forward pass logic\n",
    "\n",
    "        :return: Model output\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"\n",
    "        Model summary\n",
    "        \"\"\"\n",
    "        model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "        self.logger.info('Trainable parameters: {}'.format(params))\n",
    "        self.logger.info(self)\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Model prints with number of trainable parameters\n",
    "        \"\"\"\n",
    "        model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "        return super(BaseModel, self).__str__() + '\\nTrainable parameters: {}'.format(params)\n",
    "        # print(super(BaseModel, self))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T09:30:11.213421Z",
     "start_time": "2020-07-03T09:30:11.117759Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# F.max_pool2d needs kernel_size and stride. If only one argument is passed, \n",
    "# then kernel_size = stride\n",
    "\n",
    "from torchparse import parse_cfg\n",
    "\n",
    "# Architecture inspiration from: https://github.com/keunwoochoi/music-auto_tagging-keras\n",
    "class AudioCRNN(BaseModel):\n",
    "    def __init__(self, classes, config={}, state_dict=None):\n",
    "        super(AudioCRNN, self).__init__(config)\n",
    "        self.datasets = {}\n",
    "        in_chan = 2 if config['transforms']['args']['channels'] == 'stereo' else 1\n",
    "\n",
    "        self.classes = classes\n",
    "        self.lstm_units = 64\n",
    "        self.lstm_layers = 2\n",
    "        self.spec = MelspectrogramStretch(hop_length=None, \n",
    "                                num_mels=128, \n",
    "                                fft_length=2048, \n",
    "                                norm='whiten', \n",
    "                                stretch_param=[0.4, 0.4])\n",
    "\n",
    "        # shape -> (channel, freq, token_time)\n",
    "        self.net = parse_cfg(config['cfg'], in_shape=[in_chan, self.spec.n_mels, 400])\n",
    "\n",
    "    def _many_to_one(self, t, lengths):\n",
    "        return t[torch.arange(t.size(0)), lengths - 1]\n",
    "\n",
    "    def modify_lengths(self, lengths):\n",
    "        def safe_param(elem):\n",
    "            return elem if isinstance(elem, int) else elem[0]\n",
    "        \n",
    "        for name, layer in self.net['convs'].named_children():\n",
    "            #if name.startswith(('conv2d','maxpool2d')):\n",
    "            if isinstance(layer, (nn.Conv2d, nn.MaxPool2d)):\n",
    "                p, k, s = map(safe_param, [layer.padding, layer.kernel_size,layer.stride]) \n",
    "                lengths = ((lengths + 2*p - k)//s + 1).long()\n",
    "\n",
    "        return torch.where(lengths > 0, lengths, torch.tensor(1, device=lengths.device))\n",
    "\n",
    "    def forward(self, batch):    \n",
    "        x, lengths= batch['audio'], batch['lengths'] # unpacking seqs, lengths and srs\n",
    "        # x-> (batch, time, channel)\n",
    "        x = x.unsqueeze(2) # add channel dim\n",
    "        # x-> (batch, channel, time)\n",
    "        xt = x.float().transpose(1,2)\n",
    "        # xt -> (batch, channel, freq, time)\n",
    "        xt, lengths = self.spec(xt, lengths)                \n",
    "\n",
    "        # (batch, channel, freq, time)\n",
    "        xt = self.net['convs'](xt)\n",
    "        lengths = self.modify_lengths(lengths)\n",
    "\n",
    "        # xt -> (batch, time, freq, channel)\n",
    "        x = xt.transpose(1, -1)\n",
    "\n",
    "        # xt -> (batch, time, channel*freq)\n",
    "        batch, time = x.size()[:2]\n",
    "        x = x.reshape(batch, time, -1)\n",
    "        x_pack = torch.nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True)\n",
    "    \n",
    "        # x -> (batch, time, lstm_out)\n",
    "        x_pack, hidden = self.net['recur'](x_pack)\n",
    "        x, _ = torch.nn.utils.rnn.pad_packed_sequence(x_pack, batch_first=True)\n",
    "        \n",
    "        # (batch, lstm_out)\n",
    "        x = self._many_to_one(x, lengths)\n",
    "        # (batch, classes)\n",
    "        x = self.net['dense'](x)\n",
    "\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            out_raw = self.forward( x )\n",
    "            out = torch.exp(out_raw)\n",
    "            max_ind = out.argmax().item()        \n",
    "            return self.classes[max_ind], out[:,max_ind].item()\n",
    "\n",
    "    def getDatasetInfo(self):\n",
    "        dataset_type = {\"sample_rate\": 48000}\n",
    "        dataset_params = {\"fixed_padding\": False}\n",
    "        return dataset_type, dataset_params\n",
    "    \n",
    "    def setDataset(self, split_mode, dataset):\n",
    "        self.datasets[split_mode] = dataset\n",
    "        \n",
    "    def getDataLoader(self, split_mode, **params):\n",
    "        dataset = self.datasets[split_mode]\n",
    "        return DataLoader(dataset, collate_fn=dataset.pad_seq, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T10:48:37.711255Z",
     "start_time": "2020-06-09T10:45:01.736135Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/1687 [00:00<00:08, 189.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:06<00:00, 261.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:\t0.8494368701837581\n",
      "\tPrecision:\t0.8341121495327103\n",
      "\tRecall:   \t0.864406779661017\n",
      "\tF1-score:\t0.8489892984542212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 29/1687 [00:00<00:05, 285.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] loss: 0.405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:05<00:00, 288.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:\t0.8429164196799052\n",
      "\tPrecision:\t0.8058887677208287\n",
      "\tRecall:   \t0.8946731234866828\n",
      "\tF1-score:\t0.8479632816982214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 32/1687 [00:00<00:05, 314.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] loss: 0.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:06<00:00, 279.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:\t0.8506224066390041\n",
      "\tPrecision:\t0.8072805139186295\n",
      "\tRecall:   \t0.9128329297820823\n",
      "\tF1-score:\t0.8568181818181818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 27/1687 [00:00<00:06, 269.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] loss: 0.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:05<00:00, 285.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:\t0.8761114404267931\n",
      "\tPrecision:\t0.8642266824085005\n",
      "\tRecall:   \t0.8861985472154964\n",
      "\tF1-score:\t0.8750747160789002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 32/1687 [00:00<00:05, 312.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] loss: 0.328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:06<00:00, 278.85it/s]\n",
      "  2%|▏         | 27/1687 [00:00<00:06, 267.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:\t0.8790752815649081\n",
      "\tPrecision:\t0.8676122931442081\n",
      "\tRecall:   \t0.8886198547215496\n",
      "\tF1-score:\t0.8779904306220097\n",
      "Finished Training\n",
      "Validate:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:05<00:00, 285.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:\t0.8790752815649081\n",
      "\tPrecision:\t0.8676122931442081\n",
      "\tRecall:   \t0.8886198547215496\n",
      "\tF1-score:\t0.8779904306220097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = SpectrogramCNN().cuda()\n",
    "#print(model)\n",
    "model.float()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_loader = DataLoader(audio_set_tr, batch_size=32)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        data = [item.cuda() for item in data] # move to gpu\n",
    "        x, labels = data[:2], data[-1]\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(x)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # track statistics\n",
    "        running_loss += loss.item()\n",
    "    #print(outputs[:10])\n",
    "    \n",
    "    print('[%d] loss: %.3f' % (epoch + 1, running_loss / (i+1)))\n",
    "    validate(model)\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "print(\"Validate:\")\n",
    "validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T10:49:07.242604Z",
     "start_time": "2020-06-09T10:49:01.670957Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:05<00:00, 303.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:\t0.8790752815649081\n",
      "\tPrecision:\t0.8676122931442081\n",
      "\tRecall:   \t0.8886198547215496\n",
      "\tF1-score:\t0.8779904306220097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T10:49:09.696476Z",
     "start_time": "2020-06-09T10:49:09.681666Z"
    }
   },
   "outputs": [],
   "source": [
    "model_state_dict_path = \"/nfs/students/summer-term-2020/project-4/data/models/SpectrogramBasedCNN.pt\"\n",
    "torch.save(model.state_dict(), model_state_dict_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
